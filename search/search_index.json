{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Allocation Optimization Tooling Documentation \u00b6 Table of Content \u00b6 1. General 2. Quickstart 3. Usage and Parameters 4. Indexing Rewards 5. Architecture 6. Developer 7. Caution 8. Changelog 9. Roadmap Feedback \u00b6 To improve the tool, we look forward to your feedback. We would like to know which additional parameters would be relevant for you to tailor the optimization process more to the individual indexer. Furthermore, we would be interested to know which additional metrics you would like to see to track the performance of the indexer. Anyblock Analytics and Contact \u00b6 Check out anyblockanalytics.com . We started participating in TheGraph ecosystem in the incentivized testnet as both indexers and curators and are Mainnet indexers from the start. Besides professionally running blockchain infrastructure for rpc and data, we can provide benefits through our data analytics and visualization expertise as well as ecosystem tool building. Contact: Discord: yarkin#5659 E-Mail: yarkin@anyblockanalytics.com","title":"Allocation Optimization Tooling Documentation"},{"location":"#allocation-optimization-tooling-documentation","text":"","title":"Allocation Optimization Tooling Documentation"},{"location":"#table-of-content","text":"1. General 2. Quickstart 3. Usage and Parameters 4. Indexing Rewards 5. Architecture 6. Developer 7. Caution 8. Changelog 9. Roadmap","title":"Table of Content"},{"location":"#feedback","text":"To improve the tool, we look forward to your feedback. We would like to know which additional parameters would be relevant for you to tailor the optimization process more to the individual indexer. Furthermore, we would be interested to know which additional metrics you would like to see to track the performance of the indexer.","title":"Feedback"},{"location":"#anyblock-analytics-and-contact","text":"Check out anyblockanalytics.com . We started participating in TheGraph ecosystem in the incentivized testnet as both indexers and curators and are Mainnet indexers from the start. Besides professionally running blockchain infrastructure for rpc and data, we can provide benefits through our data analytics and visualization expertise as well as ecosystem tool building. Contact: Discord: yarkin#5659 E-Mail: yarkin@anyblockanalytics.com","title":"Anyblock Analytics and Contact"},{"location":"1.%20General/","text":"General \ud83c\udf1d \u00b6 First of all, check out 7. Caution . Check out the 2. Quickstart Guide on how to get started with this application. The 2. Quickstart#\ud83d\udcab Installation provides you with the necessary information to install this project on mac os or linux. In 3. Usage and Parameters all relevant and optional parameters and use-cases are explained. Also feel free to check out the demo screencast of the web application and the CLI screencast . 8. Changelog provides changes, enhancments and bug fixes for each released version. Navigate to the 9. Roadmap to check out what is being worked on and what is yet to come. Do you want to get further insights into the indexing reward calcuation? Navigate to 4. Indexing Rewards . 6. Developer and 5. Architecture show resources to better understand and contribute to the development and improve the tool. \u26a0\ufe0f Automatic Allocations \u00b6 The possibility of running the allocation script automatically is now pushed to the main repository. But be careful , there are still many edge cases where the script doesn't work like desired. Allocations to broken subgraph leads to problems in the automatic deallocation. If broken allocations are created, you have to manually close these allocations with a 0x0 POI. See The Graph Academy - Manually Closing Allocations . It is recommended to use the semi-automated way of using the tooling. So for the cli tool set the flag --automation to false (default false). And in the dropdown in the web application set the automation to false. Impact and Goal \u00b6 Allocations are a very important tool for indexers. Depending on the amount of allocations and the distribution of allocations on different subgraphs the indexing reward is calculated. Of course, this could be done manually - or a rule for the distribution of the stake could be set in advance. However, this might lead to not getting the optimal indexing reward. Therefore, we developed a tool (contributions appreciated) that calculates the optimal allocation distribution using optimization algorithms . For this purpose, the relevant variables in the indexing reward formula are queried using the meta subgraph, these are transferred to a linear optimization model and the model calculates the optimal distribution of the allocations on the different subgraphs. The tool creates an allocation script ( script.txt ) that can be used to change the allocations. It is possible to supply different parameters such as indexer address , parallel allocations , threshold , maximal allocation in % per Subgraph . The thresholds can be set as the minimum percentage increase of the indexing rewards and also taking into account the transaction costs for reallocations. The goal is to provide TheGraph indexers a tool to gain the highest possible return of indexing rewards from their invested stake and to react to changes in the ecosystem in an automated way. The optimization process takes every allocation and distribution of allocations and signals into consideration. After every successful optimization the results for the next optimization will differ from the previous one. It is an ever changing process of optimization because the relevant variables for the formula change. Therefore everyone who would use our allocation optimization script would benefit from it. Manually keeping track of changing circumstances in the ecosystem and distribution would be too time consuming. The goal is to provide indexers with automation and value in the allocation process without having to worry much about the allocation distribution and indexing reward formula. This would simplify the work and optimize the outcome of one aspect of being in indexer, making this role more accessible and attractive, therefore helping to decentralize this part of the ecosystem even more. All participants would benefit, as their costs decrease / profits would increase and they would be relieved of the work of manual allocation. As an additional benefit for the ecosystem, the optimized allocation distribution in the subgraphs improves. The ecosystem would benefit because an optimal distribution would not give a few subgraphs the most allocations (the best known or largest projects), but the indexing rewards formula can also make it worthwhile to allocate to smaller subgraphs, which is time-consuming to calculate manually. Feedback \u00b6 To improve the tool, we look forward to your feedback. We would like to know which additional parameters would be relevant for you to tailor the optimization process more to the individual indexer. Furthermore, we would be interested to know which additional metrics you would like to see to track the performance of the indexer. Anyblock Analytics and Contact \u00b6 Check out anyblockanalytics.com . We started participating in TheGraph ecosystem in the incentivized testnet as both indexers and curators and are Mainnet indexers from the start. Besides professionally running blockchain infrastructure for rpc and data, we can provide benefits through our data analytics and visualization expertise as well as ecosystem tool building. Contact: Discord: yarkin#5659 E-Mail: yarkin@anyblockanalytics.com","title":"General \ud83c\udf1d"},{"location":"1.%20General/#general","text":"First of all, check out 7. Caution . Check out the 2. Quickstart Guide on how to get started with this application. The 2. Quickstart#\ud83d\udcab Installation provides you with the necessary information to install this project on mac os or linux. In 3. Usage and Parameters all relevant and optional parameters and use-cases are explained. Also feel free to check out the demo screencast of the web application and the CLI screencast . 8. Changelog provides changes, enhancments and bug fixes for each released version. Navigate to the 9. Roadmap to check out what is being worked on and what is yet to come. Do you want to get further insights into the indexing reward calcuation? Navigate to 4. Indexing Rewards . 6. Developer and 5. Architecture show resources to better understand and contribute to the development and improve the tool.","title":"General \ud83c\udf1d"},{"location":"1.%20General/#automatic-allocations","text":"The possibility of running the allocation script automatically is now pushed to the main repository. But be careful , there are still many edge cases where the script doesn't work like desired. Allocations to broken subgraph leads to problems in the automatic deallocation. If broken allocations are created, you have to manually close these allocations with a 0x0 POI. See The Graph Academy - Manually Closing Allocations . It is recommended to use the semi-automated way of using the tooling. So for the cli tool set the flag --automation to false (default false). And in the dropdown in the web application set the automation to false.","title":"\u26a0\ufe0f Automatic Allocations"},{"location":"1.%20General/#impact-and-goal","text":"Allocations are a very important tool for indexers. Depending on the amount of allocations and the distribution of allocations on different subgraphs the indexing reward is calculated. Of course, this could be done manually - or a rule for the distribution of the stake could be set in advance. However, this might lead to not getting the optimal indexing reward. Therefore, we developed a tool (contributions appreciated) that calculates the optimal allocation distribution using optimization algorithms . For this purpose, the relevant variables in the indexing reward formula are queried using the meta subgraph, these are transferred to a linear optimization model and the model calculates the optimal distribution of the allocations on the different subgraphs. The tool creates an allocation script ( script.txt ) that can be used to change the allocations. It is possible to supply different parameters such as indexer address , parallel allocations , threshold , maximal allocation in % per Subgraph . The thresholds can be set as the minimum percentage increase of the indexing rewards and also taking into account the transaction costs for reallocations. The goal is to provide TheGraph indexers a tool to gain the highest possible return of indexing rewards from their invested stake and to react to changes in the ecosystem in an automated way. The optimization process takes every allocation and distribution of allocations and signals into consideration. After every successful optimization the results for the next optimization will differ from the previous one. It is an ever changing process of optimization because the relevant variables for the formula change. Therefore everyone who would use our allocation optimization script would benefit from it. Manually keeping track of changing circumstances in the ecosystem and distribution would be too time consuming. The goal is to provide indexers with automation and value in the allocation process without having to worry much about the allocation distribution and indexing reward formula. This would simplify the work and optimize the outcome of one aspect of being in indexer, making this role more accessible and attractive, therefore helping to decentralize this part of the ecosystem even more. All participants would benefit, as their costs decrease / profits would increase and they would be relieved of the work of manual allocation. As an additional benefit for the ecosystem, the optimized allocation distribution in the subgraphs improves. The ecosystem would benefit because an optimal distribution would not give a few subgraphs the most allocations (the best known or largest projects), but the indexing rewards formula can also make it worthwhile to allocate to smaller subgraphs, which is time-consuming to calculate manually.","title":"Impact and Goal"},{"location":"1.%20General/#feedback","text":"To improve the tool, we look forward to your feedback. We would like to know which additional parameters would be relevant for you to tailor the optimization process more to the individual indexer. Furthermore, we would be interested to know which additional metrics you would like to see to track the performance of the indexer.","title":"Feedback"},{"location":"1.%20General/#anyblock-analytics-and-contact","text":"Check out anyblockanalytics.com . We started participating in TheGraph ecosystem in the incentivized testnet as both indexers and curators and are Mainnet indexers from the start. Besides professionally running blockchain infrastructure for rpc and data, we can provide benefits through our data analytics and visualization expertise as well as ecosystem tool building. Contact: Discord: yarkin#5659 E-Mail: yarkin@anyblockanalytics.com","title":"Anyblock Analytics and Contact"},{"location":"2.%20Quickstart/","text":"\ud83d\ude80Quickstart \u00b6 There are different options to run the allocation optimization script. You can either run the optimization via a CLI script or with the Streamlit Web Application . If you are interested in a more visual presentation of the optimization process, it is recommended to use the streamlit web application. Currently a docker container is work in progress. This quickstart explains the local installation of the allocation script. Demo Web Application: Demo CLI tool: \u26a0\ufe0f Automatic Allocations \u00b6 The possibility of running the allocation script automatically is now pushed to the main repository. But be careful , there are still many edge cases where the script doesn't work like desired. Allocations to broken subgraph leads to problems in the automatic deallocation. If broken allocations are created, you have to manually close these allocations with a 0x0 POI. See The Graph Academy - Manually Closing Allocations . It is recommended to use the semi-automated way of using the tooling. So for the cli tool set the flag --automation to false (default false). And in the dropdown in the web application set the automation to false. \ud83d\udcab Installation \u00b6 \ud83c\udf4f Mac OS \u00b6 Make sure to install Homebrew Install GLPK (GNU Linear Programming Kit). It is a open source library used for large-scale linear programming, mixed integer programming and other mathematical problems. brew install glpk \ud83d\udc27 Linux \u00b6 Open a Terminal Install GLPK (GNU Linear Programming Kit). It is an open source library used for large-scale linear programming, mixed integer programming and other mathematical problems. It also requires some dependencies to be installed. sudo apt-get install glpk-utils libglpk-dev glpk-doc python-glpk General \u00b6 If Python is not installed on your system yet, it is necessary to install it either directly via the command line or to download the installation file from the web. Subsequently, it is necessary to install the Python package manager pip. Best, open a command line and execute the following command: python3 -m pip install --user --upgrade pip Make sure python and pip is installed correctly. python \u2013\u2013version pip3 --version It is always recommended to create new projects in virtual environments. This way the packages can be managed separately, you can create an isolated Python installation and you do not influence the system Python interpreter. Using virtual environments requires the installation of the \u201cvirtualenv\u201d package (for further documentation, visit this tutorial ). python3 -m pip install --user virtualenv Clone the repository into the desired directory: git clone https://github.com/anyblockanalytics/thegraph-allocation-optimization.git After creating the directory, we need to change to this folder and create a virtual environment. python3 -m venv env And then the virtual environment can be activated source env/bin/activate Now the requirments.txt file can be installed via pip pip install -r requirements.txt Open the .env_example file and change the rpc key, postgres connection, slack alerting webhook (if a slack alerting is wanted) and the Indexer ID to your credentials. After changing the values, rename the file to .env Open the config.json file. If you want to provide subgraphs to the blacklist manually, you can include the subgraphs or subgraph developers in this file. Now everything should be installed. Start a terminal in the repository directory and run the script to check if everything works: python ./main.py --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --blacklist Some Linux distros may require the following command: python3 ./main.py --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --blacklist It is also possible to run the script on the The Graph Testnet python ./main.py --indexer_id 0xbed8e8c97cf3accc3a9dfecc30700b49e30014f3 --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --network \"testnet\" ``` 13. Start the streamlit server: ```shell streamlit run app.py Open your web browser and navigate to http://localhost:8501/ the streamlit web app should open. Navigate to 3. Usage and Parameters for further configurations and explanation of all parameters. Docker \u00b6 You can create a docker container with the following command. But before building the docker container, be sure to change the .env_example file to .env example and add your RPC credentials. docker build -t allocation-optimization . Running the CLI Tool is possible with the command: docker container run allocation-optimization --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --app \"script\" The entrypoint of the docker container is \"python\", \"main.py\". Running the web app in the docker container can be achieved with: docker container run allocation-optimization --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --app \"app\"","title":"\ud83d\ude80Quickstart"},{"location":"2.%20Quickstart/#quickstart","text":"There are different options to run the allocation optimization script. You can either run the optimization via a CLI script or with the Streamlit Web Application . If you are interested in a more visual presentation of the optimization process, it is recommended to use the streamlit web application. Currently a docker container is work in progress. This quickstart explains the local installation of the allocation script. Demo Web Application: Demo CLI tool:","title":"\ud83d\ude80Quickstart"},{"location":"2.%20Quickstart/#automatic-allocations","text":"The possibility of running the allocation script automatically is now pushed to the main repository. But be careful , there are still many edge cases where the script doesn't work like desired. Allocations to broken subgraph leads to problems in the automatic deallocation. If broken allocations are created, you have to manually close these allocations with a 0x0 POI. See The Graph Academy - Manually Closing Allocations . It is recommended to use the semi-automated way of using the tooling. So for the cli tool set the flag --automation to false (default false). And in the dropdown in the web application set the automation to false.","title":"\u26a0\ufe0f Automatic Allocations"},{"location":"2.%20Quickstart/#installation","text":"","title":"\ud83d\udcab Installation"},{"location":"2.%20Quickstart/#mac-os","text":"Make sure to install Homebrew Install GLPK (GNU Linear Programming Kit). It is a open source library used for large-scale linear programming, mixed integer programming and other mathematical problems. brew install glpk","title":"\ud83c\udf4f Mac OS"},{"location":"2.%20Quickstart/#linux","text":"Open a Terminal Install GLPK (GNU Linear Programming Kit). It is an open source library used for large-scale linear programming, mixed integer programming and other mathematical problems. It also requires some dependencies to be installed. sudo apt-get install glpk-utils libglpk-dev glpk-doc python-glpk","title":"\ud83d\udc27 Linux"},{"location":"2.%20Quickstart/#general","text":"If Python is not installed on your system yet, it is necessary to install it either directly via the command line or to download the installation file from the web. Subsequently, it is necessary to install the Python package manager pip. Best, open a command line and execute the following command: python3 -m pip install --user --upgrade pip Make sure python and pip is installed correctly. python \u2013\u2013version pip3 --version It is always recommended to create new projects in virtual environments. This way the packages can be managed separately, you can create an isolated Python installation and you do not influence the system Python interpreter. Using virtual environments requires the installation of the \u201cvirtualenv\u201d package (for further documentation, visit this tutorial ). python3 -m pip install --user virtualenv Clone the repository into the desired directory: git clone https://github.com/anyblockanalytics/thegraph-allocation-optimization.git After creating the directory, we need to change to this folder and create a virtual environment. python3 -m venv env And then the virtual environment can be activated source env/bin/activate Now the requirments.txt file can be installed via pip pip install -r requirements.txt Open the .env_example file and change the rpc key, postgres connection, slack alerting webhook (if a slack alerting is wanted) and the Indexer ID to your credentials. After changing the values, rename the file to .env Open the config.json file. If you want to provide subgraphs to the blacklist manually, you can include the subgraphs or subgraph developers in this file. Now everything should be installed. Start a terminal in the repository directory and run the script to check if everything works: python ./main.py --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --blacklist Some Linux distros may require the following command: python3 ./main.py --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --blacklist It is also possible to run the script on the The Graph Testnet python ./main.py --indexer_id 0xbed8e8c97cf3accc3a9dfecc30700b49e30014f3 --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --network \"testnet\" ``` 13. Start the streamlit server: ```shell streamlit run app.py Open your web browser and navigate to http://localhost:8501/ the streamlit web app should open. Navigate to 3. Usage and Parameters for further configurations and explanation of all parameters.","title":"General"},{"location":"2.%20Quickstart/#docker","text":"You can create a docker container with the following command. But before building the docker container, be sure to change the .env_example file to .env example and add your RPC credentials. docker build -t allocation-optimization . Running the CLI Tool is possible with the command: docker container run allocation-optimization --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --app \"script\" The entrypoint of the docker container is \"python\", \"main.py\". Running the web app in the docker container can be achieved with: docker container run allocation-optimization --indexer_id 0x453b5e165cf98ff60167ccd3560ebf8d436ca86c --max_percentage 0.2 --threshold 20 --parallel_allocations 1 --no-subgraph-list --app \"app\"","title":"Docker"},{"location":"3.%20Usage%20and%20Parameters/","text":"Usage and Parameters \u00b6 In this part of the documentation the available parameters for the allocation optimization process are explained \ud83d\udca1 and use-cases are shown. The user of this allocation optimization script can adjust the allocation optimization process according to their wishes through some parameters. The following adjustments can be made: A blacklist can be created. The subgraphs in the blacklist are not considered in the allocation process. The script creates a blacklist using various functions to avoid possible bot-bait subgraphs. The script can then blacklist specific subgraph developers, exclude subgraphs with error status or an outdated version, and blacklist subgraphs based on the sync status of the local indexer database. A predefined subgraph list can be passed. Only these subgraphs should be considered in the allocation process and the stake should be distributed appropriately to these subgraphs. Slack alerting can be integrated using webhooks. Each execution of the script creates an alert in a defined Slack channel if the threshold for a possible reallocation has been reached. Threshold: With the threshold a percentage limit is determined. If this threshold is exceeded, a reallocation is appropriate and the tool creates a script.txt file containing the relevant commands for a reallocation. And many more parameters which are described in the 3. Usage and Parameters#Available Parameters The product to be built will allow for: Visualization of the optimization process in a web app, which users can interact with to input various parameters such as the amount of stake to be allocated, maximum number of allocations, and maximum number of subgraphs on which to allocate, etc. Visualization of the historic and current rewards from Indexing in the web app Scheduling when such optimization processes should take place while automating the implementation of resulting suggestions. Available Parameters \u00b6 indexer_id : It is necessary to supply the indexer address. max_percentage : With max_percentage (a value between 0.0 - 1.0 ) it is possible to set an upper limit in how much (percentage-wise) an allocation on one single subgraph can take. In the current status, the optimization often allocates the entire stake into one single subgraph (possibly this won't change, even when there are many subgraphs). The optimizations allocates the entire stake into one subgraph, because this (often) maximizes the indexing rewards. But sometimes it is not useful to allocate everything into one subgraph (risk diversification, ...). Therefore with max_percentage it is possible to limit the amount of stake one single subgraph can take. If it is set to 0.9, and you have a stake of 1.5M GRT, then the single subgraph can at most get 1.35M GRT allocated. The remainder is allocated to the next optimal subgraph, or is split among the rest. We at Anyblock like to diversify, so we set max_percentage to 0.2 threshold : Set the threshold (in %) when an allocation script will be created. Takes a value between 0 - Infinity . If your current weekly Indexing Rewards are 5000 and the threshold is set to 10 . The optimization has to atleast result in an increase of 10% in indexing rewards to create an allocation script. BUT the calculation of the threshold takes also the transaction costs into account. This means the indexing rewards have to be higher than 10% compared to the previous indexing rewards AFTER the transaction costs for the reallocation have been subtracted. Our threshold is 20 %. parallel_allocations : Amoutn of parallel allocations (required for creating the script.txt file). Basically splits the allocation amount into subsets of the supplied parallel allocation amount. (SOON TO BE DEPRECIATED \u26a0\ufe0f) no-subgraph-list : Disables the config.json, so no manual subgraph list is provided. (Default) subgraph-list : utilizes the provided list in config.json as subgraphs that should be considered for the optimization. blacklist : tells the script to ignore the blacklisted subgraphs in config.json. Also the blacklist will be created with the functions in subgraphs_health_check.py . threshold_interval: Define the interval which is used for calculating the threshold requirment. Currently the recommended threshold interval is \"weekly\". Setting the threshold interval to weekly leads the optimization script to calculate threshold requirments based on weekly indexing rewards. reserve_stake: Enables the indexer to define a dedicated amount of stake which should not be considered in the optimization. This reserve stake will not be allocated! min_allocation: Set the minimum allocation in GRT per subgraph. If this value is above 0, every deployed subgraph will get the minimum allocation amount. ATTENTION \ud83d\udea8: Setting this value above 0 leads to massive increases in transaction costs . Also setting this too high, can lead to a non feasible solution which leads to errors in the allocation optimization script. If the min_allocation is too high, the available stake can be insufficient. min_allocated_grt_subgraph: Defines the minimum GRT allocation requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT allocated than the min_allocated_grt_subgraph, then it will not be considered in the optimization process. min_signalled_grt_subgraph: Defines the minimum GRT signal requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT signalled than the min_signalled_grt_subgraph, then it will not be considered in the optimization process. slack_alerting: Enables the user to configure a slack alerting in a dedicated slack channel. Outputs if the optimization reached the threshold and how much increase / decrease in rewards is expected after the optimization. Configure the webhook and channel in the .env file. network : Select the network for the optimization run. Can either be set to \"mainnet\" (default) or \"testnet\". automation : Activates the automation parameter. If --automation is used, the script automatically removes the active allocations, reallocates with the optimized results (if threshold is reached) and checks if changes are written to the chain.(Not Activated on default) ignore_tx_costs : Ignores gas costs for allocation opening / closings for the threshold reached calculation. CLI - Tool \u00b6 The CLI tool should be able to be used to automate the optimization and allocation process. In the future, the CLI tool will be executed with the help of a cron job in defined intervals and when the threshold is reached, the allocations will be automatically adjusted according to the optimization. The CLI tool is also used to run the optimization script without having to call a web interface. No streamlit web server is required to run the script. The CLI version supports the same parameterizations as the web interface. The script currently outputs two files: script_never.txt and script.txt . In future releases the optimization script will directly work with the indexer agent endpoint and communicate the allocation creation / closing with the help of graphQL mutations. script_never.txt \u00b6 The script_never.txt file contains the necessary commands that must be entered to drop all current allocations at the end of the current epoch. This is necessary to be able to use the script.txt and reallocate. The script_never.txt takes all subgraphs available into consideration and clears all allocations. It should be adapted if this is not the desired outcome. An example of a script_never.txt file: graph indexer rules set QmbYFfUKETrUwTQ7z8VD87KFoYJps8TGsSbM6m8bi6TaKG decisionBasis never && \\ graph indexer rules set QmTj6fHgHjuKKm43YL3Sm2hMvMci4AkFzx22Mdo9W3dyn8 decisionBasis never && \\ graph indexer rules get all --merged && \\ graph indexer cost get all ### [](https://github.com/anyblockanalytics/thegraph-allocation-optimization#scripttxt) script.txt \u00b6 The script file contains the necessary commands that must be entered to change the allocations and adjust them according to the optimization. The allocation script is general. It should be adapted according to the use-case. An example of a script.txt file: graph indexer rules set QmRhYzT8HEZ9LziQhP6JfNfd4co9A7muUYQhPMJsMUojSF allocationAmount 406350.00 parallelAllocations 4 decisionBasis always && \\ graph indexer cost set model QmRhYzT8HEZ9LziQhP6JfNfd4co9A7muUYQhPMJsMUojSF default.agora && \\ graph indexer cost set variables QmRhYzT8HEZ9LziQhP6JfNfd4co9A7muUYQhPMJsMUojSF '{}' && \\ graph indexer rules get all --merged && \\graph indexer cost get all automation \u00b6 If the flag --automation is set, the script automatically closes and opens reallocation if the threshold is reached. This requires setting the INDEXER_MANAGEMENT_ENDPOINT in the environment file. The default is set to \"127.0.0.1:18000\". If the threshold is reached, the allocation queries all active allocations, sets the indexingRules to never and looks up if the AllocationClosed Event was successfully written on the blockchain. Web3.py with EventFilters is used to check for succesfull \"AllocationClosed\" and \"AllocationsCreated\" events. The script waits until all AllocationClosings are written on chain and then moves on to setIndexingRules always for the optimization results. The script checks with web3.py eventfilters if the allocation creations are written on the blockchain. Streamlit App \u00b6 Check out the screencast of the web app: It is possible to parameterize the optimization run on the sidebar. After setting up the prefered settings, click on the button \"run optimization\". If the blacklist parameter is checked, the optimization run will take a while ( less than 2 minutes ). After running the optimization script, the dashboard is further populated. Data from previous optimizations as JSON Price Data (ETH-USD, GRT-USD, Gas Price in Gwei) Historical performance for Closed/Active/Combined allocations Data Table with allocation data by date DIY Chart Builder (WIP) Performance Metrics which visualize rewards per hour and optimized allocations on a timeline Optimization run metrics: Indexer stake, current rewards (hour/day/weekly/yearly) Pending rewards, active allocations, average stake/signal ratio, average hourly rewards Current allocation table Distribution of rewards/stake signal ratio Threshold pop up, Information about the subgraphs the optimization tool recommends. (Boxes with dedicated image, description and metrics) Output of allocation and allocation closing commands The web app makes it possible to follow the optimization process in a simple way. The results are visualized and recommendations for action are suggested. If the results are satisfactory, the commands can be copied for reallocation and executed in the Indexer CLI. The web app represents a semi-automated approach, where allocations are not yet set or closed automatically. The Web App also serves to build trust in the tool so that users know how the optimization works before they use the fully automated version.","title":"Usage and Parameters"},{"location":"3.%20Usage%20and%20Parameters/#usage-and-parameters","text":"In this part of the documentation the available parameters for the allocation optimization process are explained \ud83d\udca1 and use-cases are shown. The user of this allocation optimization script can adjust the allocation optimization process according to their wishes through some parameters. The following adjustments can be made: A blacklist can be created. The subgraphs in the blacklist are not considered in the allocation process. The script creates a blacklist using various functions to avoid possible bot-bait subgraphs. The script can then blacklist specific subgraph developers, exclude subgraphs with error status or an outdated version, and blacklist subgraphs based on the sync status of the local indexer database. A predefined subgraph list can be passed. Only these subgraphs should be considered in the allocation process and the stake should be distributed appropriately to these subgraphs. Slack alerting can be integrated using webhooks. Each execution of the script creates an alert in a defined Slack channel if the threshold for a possible reallocation has been reached. Threshold: With the threshold a percentage limit is determined. If this threshold is exceeded, a reallocation is appropriate and the tool creates a script.txt file containing the relevant commands for a reallocation. And many more parameters which are described in the 3. Usage and Parameters#Available Parameters The product to be built will allow for: Visualization of the optimization process in a web app, which users can interact with to input various parameters such as the amount of stake to be allocated, maximum number of allocations, and maximum number of subgraphs on which to allocate, etc. Visualization of the historic and current rewards from Indexing in the web app Scheduling when such optimization processes should take place while automating the implementation of resulting suggestions.","title":"Usage and Parameters"},{"location":"3.%20Usage%20and%20Parameters/#available-parameters","text":"indexer_id : It is necessary to supply the indexer address. max_percentage : With max_percentage (a value between 0.0 - 1.0 ) it is possible to set an upper limit in how much (percentage-wise) an allocation on one single subgraph can take. In the current status, the optimization often allocates the entire stake into one single subgraph (possibly this won't change, even when there are many subgraphs). The optimizations allocates the entire stake into one subgraph, because this (often) maximizes the indexing rewards. But sometimes it is not useful to allocate everything into one subgraph (risk diversification, ...). Therefore with max_percentage it is possible to limit the amount of stake one single subgraph can take. If it is set to 0.9, and you have a stake of 1.5M GRT, then the single subgraph can at most get 1.35M GRT allocated. The remainder is allocated to the next optimal subgraph, or is split among the rest. We at Anyblock like to diversify, so we set max_percentage to 0.2 threshold : Set the threshold (in %) when an allocation script will be created. Takes a value between 0 - Infinity . If your current weekly Indexing Rewards are 5000 and the threshold is set to 10 . The optimization has to atleast result in an increase of 10% in indexing rewards to create an allocation script. BUT the calculation of the threshold takes also the transaction costs into account. This means the indexing rewards have to be higher than 10% compared to the previous indexing rewards AFTER the transaction costs for the reallocation have been subtracted. Our threshold is 20 %. parallel_allocations : Amoutn of parallel allocations (required for creating the script.txt file). Basically splits the allocation amount into subsets of the supplied parallel allocation amount. (SOON TO BE DEPRECIATED \u26a0\ufe0f) no-subgraph-list : Disables the config.json, so no manual subgraph list is provided. (Default) subgraph-list : utilizes the provided list in config.json as subgraphs that should be considered for the optimization. blacklist : tells the script to ignore the blacklisted subgraphs in config.json. Also the blacklist will be created with the functions in subgraphs_health_check.py . threshold_interval: Define the interval which is used for calculating the threshold requirment. Currently the recommended threshold interval is \"weekly\". Setting the threshold interval to weekly leads the optimization script to calculate threshold requirments based on weekly indexing rewards. reserve_stake: Enables the indexer to define a dedicated amount of stake which should not be considered in the optimization. This reserve stake will not be allocated! min_allocation: Set the minimum allocation in GRT per subgraph. If this value is above 0, every deployed subgraph will get the minimum allocation amount. ATTENTION \ud83d\udea8: Setting this value above 0 leads to massive increases in transaction costs . Also setting this too high, can lead to a non feasible solution which leads to errors in the allocation optimization script. If the min_allocation is too high, the available stake can be insufficient. min_allocated_grt_subgraph: Defines the minimum GRT allocation requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT allocated than the min_allocated_grt_subgraph, then it will not be considered in the optimization process. min_signalled_grt_subgraph: Defines the minimum GRT signal requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT signalled than the min_signalled_grt_subgraph, then it will not be considered in the optimization process. slack_alerting: Enables the user to configure a slack alerting in a dedicated slack channel. Outputs if the optimization reached the threshold and how much increase / decrease in rewards is expected after the optimization. Configure the webhook and channel in the .env file. network : Select the network for the optimization run. Can either be set to \"mainnet\" (default) or \"testnet\". automation : Activates the automation parameter. If --automation is used, the script automatically removes the active allocations, reallocates with the optimized results (if threshold is reached) and checks if changes are written to the chain.(Not Activated on default) ignore_tx_costs : Ignores gas costs for allocation opening / closings for the threshold reached calculation.","title":"Available Parameters"},{"location":"3.%20Usage%20and%20Parameters/#cli-tool","text":"The CLI tool should be able to be used to automate the optimization and allocation process. In the future, the CLI tool will be executed with the help of a cron job in defined intervals and when the threshold is reached, the allocations will be automatically adjusted according to the optimization. The CLI tool is also used to run the optimization script without having to call a web interface. No streamlit web server is required to run the script. The CLI version supports the same parameterizations as the web interface. The script currently outputs two files: script_never.txt and script.txt . In future releases the optimization script will directly work with the indexer agent endpoint and communicate the allocation creation / closing with the help of graphQL mutations.","title":"CLI - Tool"},{"location":"3.%20Usage%20and%20Parameters/#script_nevertxt","text":"The script_never.txt file contains the necessary commands that must be entered to drop all current allocations at the end of the current epoch. This is necessary to be able to use the script.txt and reallocate. The script_never.txt takes all subgraphs available into consideration and clears all allocations. It should be adapted if this is not the desired outcome. An example of a script_never.txt file: graph indexer rules set QmbYFfUKETrUwTQ7z8VD87KFoYJps8TGsSbM6m8bi6TaKG decisionBasis never && \\ graph indexer rules set QmTj6fHgHjuKKm43YL3Sm2hMvMci4AkFzx22Mdo9W3dyn8 decisionBasis never && \\ graph indexer rules get all --merged && \\ graph indexer cost get all ### [](https://github.com/anyblockanalytics/thegraph-allocation-optimization#scripttxt)","title":"script_never.txt"},{"location":"3.%20Usage%20and%20Parameters/#scripttxt","text":"The script file contains the necessary commands that must be entered to change the allocations and adjust them according to the optimization. The allocation script is general. It should be adapted according to the use-case. An example of a script.txt file: graph indexer rules set QmRhYzT8HEZ9LziQhP6JfNfd4co9A7muUYQhPMJsMUojSF allocationAmount 406350.00 parallelAllocations 4 decisionBasis always && \\ graph indexer cost set model QmRhYzT8HEZ9LziQhP6JfNfd4co9A7muUYQhPMJsMUojSF default.agora && \\ graph indexer cost set variables QmRhYzT8HEZ9LziQhP6JfNfd4co9A7muUYQhPMJsMUojSF '{}' && \\ graph indexer rules get all --merged && \\graph indexer cost get all","title":"script.txt"},{"location":"3.%20Usage%20and%20Parameters/#automation","text":"If the flag --automation is set, the script automatically closes and opens reallocation if the threshold is reached. This requires setting the INDEXER_MANAGEMENT_ENDPOINT in the environment file. The default is set to \"127.0.0.1:18000\". If the threshold is reached, the allocation queries all active allocations, sets the indexingRules to never and looks up if the AllocationClosed Event was successfully written on the blockchain. Web3.py with EventFilters is used to check for succesfull \"AllocationClosed\" and \"AllocationsCreated\" events. The script waits until all AllocationClosings are written on chain and then moves on to setIndexingRules always for the optimization results. The script checks with web3.py eventfilters if the allocation creations are written on the blockchain.","title":"automation"},{"location":"3.%20Usage%20and%20Parameters/#streamlit-app","text":"Check out the screencast of the web app: It is possible to parameterize the optimization run on the sidebar. After setting up the prefered settings, click on the button \"run optimization\". If the blacklist parameter is checked, the optimization run will take a while ( less than 2 minutes ). After running the optimization script, the dashboard is further populated. Data from previous optimizations as JSON Price Data (ETH-USD, GRT-USD, Gas Price in Gwei) Historical performance for Closed/Active/Combined allocations Data Table with allocation data by date DIY Chart Builder (WIP) Performance Metrics which visualize rewards per hour and optimized allocations on a timeline Optimization run metrics: Indexer stake, current rewards (hour/day/weekly/yearly) Pending rewards, active allocations, average stake/signal ratio, average hourly rewards Current allocation table Distribution of rewards/stake signal ratio Threshold pop up, Information about the subgraphs the optimization tool recommends. (Boxes with dedicated image, description and metrics) Output of allocation and allocation closing commands The web app makes it possible to follow the optimization process in a simple way. The results are visualized and recommendations for action are suggested. If the results are satisfactory, the commands can be copied for reallocation and executed in the Indexer CLI. The web app represents a semi-automated approach, where allocations are not yet set or closed automatically. The Web App also serves to build trust in the tool so that users know how the optimization works before they use the fully automated version.","title":"Streamlit App"},{"location":"4.%20Indexing%20Rewards/","text":"Indexing Rewards \u00b6 General \u00b6 Indexer have a vital role to fulfill in The Graph ecosystem. This role is incentivized by two revenue streams for indexers. On the one hand, indexers are rewarded for their service in the ecosystem by receiving payments for serving queries in the networ ( query fee rebates ). And on the other hand, the 3% annual protocol-wide inflation is distributed to indexers who index subgraphs in the network. This second revenue stream are the indexing rewards . See The Graph documentation for further information. Indexing rewards come from protocol inflation which is set to 3% annual issuance. They are distributed across subgraphs based on the proportion of all curation signals on each, then distributed proportionally to indexers based on their allocated stake on that subgraph . An allocation must be closed with a valid proof of indexing (POI) that meets the standards set by the arbitration charter to be eligible for rewards. -- FAQ on The Graph Documentation : Equation \u00b6 Allocations are therefore a core aspect of The Graph ecosystem for indexers to earn indexing rewards . Based on the distribution and the amounts of allocations on different subgraphs, the indexing rewards are calculated using this formula: where \u03c9ij is the amount that Indexer i has staked on subgraph j, \u03a9j is the total amount staked on subgraph j, \u03c8j is the amount of GRT signaled for subgraph j, \u03a8 is the total amount signaled in the network and \u03a6 is the total network indexer reward denominated in GRT. One could now calculate the indexing reward manually for each subgraph and distribute its stake accordingly. An alternative to this would be to define a rule that the indexer agent uses to distribute the allocations automatically. For example, one could distribute the stake equally among all subgraphs in the network. However, this might lead to not getting the optimum indexing reward. ( Source: Discord stake-machine#1984 ) Problem Statement: How can indexing rewards be maximized so that the stake of indexers can be used most effectively without the time investment going to the extreme? Optimizing Indexing Rewards \u00b6 Since this manual approach does not yield the optimal rewards , we use the Grant to develop a tool that computes the optimal allocation distribution using optimization algorithms . The relevant data for calculating the optimal allocation distribution is fetched using the network subgraph and other data sources and fed into the linear optimization model. This model then calculates the optimal distribution of allocations on the different subgraphs, taking into account the preferences and parameterizations of the indexer . The equation for calculating the indexing rewards is a perfect example of a linear optimization problem. The equation calculates the indexing rewards for each subgraph on which the indexer has an allocation. The sum of the indexing rewards per subgraph gives the total indexing rewards of the indexer. This tool optimizes the result of this calculation. The goal is to maximize the indexing rewards . So the value that is left in the formula ( Ri ). For this purpose the variable \u03c9ij , i.e. the allocations are optimized. The objective of the optimization is to maximize the indexing rewards. Thereby different constraints are considered. The total allocations must not exceed the value of the indexer total stakes (minus the reserve stake). For each subgraph that is optimized, the variable allocation must not be less than the min_allocation (parameter). For each subgraph that is optimized, the variable allocation must not exceed the max_percentage (parameter) multiplied by the indexer total stake. For a programmatic explanation, look at this following code: data = {(df.reset_index()['Name_y'].values[j], df.reset_index()['Address'].values[j], df['id'].values[j]): { 'Allocation': df['Allocation'].values[j], 'signalledTokensTotal': df['signalledTokensTotal'].values[j], 'stakedTokensTotal': df['stakedTokensTotal'].values[j], 'SignalledNetwork': int(total_tokens_signalled) / 10 ** 18, 'indexingRewardYear': indexing_reward_year, 'indexingRewardWeek': indexing_reward_week, 'indexingRewardDay': indexing_reward_day, 'indexingRewardHour': indexing_reward_hour, 'id': df['id'].values[j]} for j in set_J} # Initialize Pyomo Variables C = data.keys() # Name of Subgraphs model = pyomo.ConcreteModel() S = len(data) # amount subgraphs model.Subgraphs = range(S) # The Variable (Allocations) that should be changed to optimize rewards model.x = pyomo.Var(C, domain=pyomo.NonNegativeReals) # formula and model model.rewards = pyomo.Objective( expr=sum((model.x[c] / (data[c]['stakedTokensTotal'] + sliced_stake)) * ( data[c]['signalledTokensTotal'] / data[c]['SignalledNetwork']) * data[c][reward_interval] for c in C), # Indexing Rewards Formula (Daily Rewards) sense=pyomo.maximize) # maximize Indexing Rewards # set constraint that allocations shouldn't be higher than total stake- reserce stake model.vol = pyomo.Constraint(expr=indexer_total_stake - reserve_stake >= sum( model.x[c] for c in C)) model.bound_x = pyomo.ConstraintList() # iterate through subgraphs and set constraints for c in C: # Allocations per Subgraph should be higher than min_allocation model.bound_x.add(model.x[c] >= min_allocation) # Allocation per Subgraph can't be higher than x % of total Allocations model.bound_x.add(model.x[c] <= max_percentage * indexer_total_stake) # set solver to glpk -> In Future this could be changeable solver = pyomo.SolverFactory('glpk') solver.solve(model, keepfiles=True)","title":"Indexing Rewards"},{"location":"4.%20Indexing%20Rewards/#indexing-rewards","text":"","title":"Indexing Rewards"},{"location":"4.%20Indexing%20Rewards/#general","text":"Indexer have a vital role to fulfill in The Graph ecosystem. This role is incentivized by two revenue streams for indexers. On the one hand, indexers are rewarded for their service in the ecosystem by receiving payments for serving queries in the networ ( query fee rebates ). And on the other hand, the 3% annual protocol-wide inflation is distributed to indexers who index subgraphs in the network. This second revenue stream are the indexing rewards . See The Graph documentation for further information. Indexing rewards come from protocol inflation which is set to 3% annual issuance. They are distributed across subgraphs based on the proportion of all curation signals on each, then distributed proportionally to indexers based on their allocated stake on that subgraph . An allocation must be closed with a valid proof of indexing (POI) that meets the standards set by the arbitration charter to be eligible for rewards. -- FAQ on The Graph Documentation :","title":"General"},{"location":"4.%20Indexing%20Rewards/#equation","text":"Allocations are therefore a core aspect of The Graph ecosystem for indexers to earn indexing rewards . Based on the distribution and the amounts of allocations on different subgraphs, the indexing rewards are calculated using this formula: where \u03c9ij is the amount that Indexer i has staked on subgraph j, \u03a9j is the total amount staked on subgraph j, \u03c8j is the amount of GRT signaled for subgraph j, \u03a8 is the total amount signaled in the network and \u03a6 is the total network indexer reward denominated in GRT. One could now calculate the indexing reward manually for each subgraph and distribute its stake accordingly. An alternative to this would be to define a rule that the indexer agent uses to distribute the allocations automatically. For example, one could distribute the stake equally among all subgraphs in the network. However, this might lead to not getting the optimum indexing reward. ( Source: Discord stake-machine#1984 ) Problem Statement: How can indexing rewards be maximized so that the stake of indexers can be used most effectively without the time investment going to the extreme?","title":"Equation"},{"location":"4.%20Indexing%20Rewards/#optimizing-indexing-rewards","text":"Since this manual approach does not yield the optimal rewards , we use the Grant to develop a tool that computes the optimal allocation distribution using optimization algorithms . The relevant data for calculating the optimal allocation distribution is fetched using the network subgraph and other data sources and fed into the linear optimization model. This model then calculates the optimal distribution of allocations on the different subgraphs, taking into account the preferences and parameterizations of the indexer . The equation for calculating the indexing rewards is a perfect example of a linear optimization problem. The equation calculates the indexing rewards for each subgraph on which the indexer has an allocation. The sum of the indexing rewards per subgraph gives the total indexing rewards of the indexer. This tool optimizes the result of this calculation. The goal is to maximize the indexing rewards . So the value that is left in the formula ( Ri ). For this purpose the variable \u03c9ij , i.e. the allocations are optimized. The objective of the optimization is to maximize the indexing rewards. Thereby different constraints are considered. The total allocations must not exceed the value of the indexer total stakes (minus the reserve stake). For each subgraph that is optimized, the variable allocation must not be less than the min_allocation (parameter). For each subgraph that is optimized, the variable allocation must not exceed the max_percentage (parameter) multiplied by the indexer total stake. For a programmatic explanation, look at this following code: data = {(df.reset_index()['Name_y'].values[j], df.reset_index()['Address'].values[j], df['id'].values[j]): { 'Allocation': df['Allocation'].values[j], 'signalledTokensTotal': df['signalledTokensTotal'].values[j], 'stakedTokensTotal': df['stakedTokensTotal'].values[j], 'SignalledNetwork': int(total_tokens_signalled) / 10 ** 18, 'indexingRewardYear': indexing_reward_year, 'indexingRewardWeek': indexing_reward_week, 'indexingRewardDay': indexing_reward_day, 'indexingRewardHour': indexing_reward_hour, 'id': df['id'].values[j]} for j in set_J} # Initialize Pyomo Variables C = data.keys() # Name of Subgraphs model = pyomo.ConcreteModel() S = len(data) # amount subgraphs model.Subgraphs = range(S) # The Variable (Allocations) that should be changed to optimize rewards model.x = pyomo.Var(C, domain=pyomo.NonNegativeReals) # formula and model model.rewards = pyomo.Objective( expr=sum((model.x[c] / (data[c]['stakedTokensTotal'] + sliced_stake)) * ( data[c]['signalledTokensTotal'] / data[c]['SignalledNetwork']) * data[c][reward_interval] for c in C), # Indexing Rewards Formula (Daily Rewards) sense=pyomo.maximize) # maximize Indexing Rewards # set constraint that allocations shouldn't be higher than total stake- reserce stake model.vol = pyomo.Constraint(expr=indexer_total_stake - reserve_stake >= sum( model.x[c] for c in C)) model.bound_x = pyomo.ConstraintList() # iterate through subgraphs and set constraints for c in C: # Allocations per Subgraph should be higher than min_allocation model.bound_x.add(model.x[c] >= min_allocation) # Allocation per Subgraph can't be higher than x % of total Allocations model.bound_x.add(model.x[c] <= max_percentage * indexer_total_stake) # set solver to glpk -> In Future this could be changeable solver = pyomo.SolverFactory('glpk') solver.solve(model, keepfiles=True)","title":"Optimizing Indexing Rewards"},{"location":"5.%20Architecture/","text":"Architecture \u00b6 The tech stack for the allocation optimization tool contains different libraries as well as tools. The used programming language is python . Let's start with the Allocation Optimization Script itself. This core module of the application contains the relevant steps to optimize the allocations so that the highest indexing rewards can be achieved according to the given parameters. Core Functionality \u00b6 The script is based on the Pyomo . optimization modeling language, which is based on Python and is open source. With the help of Pyomo, it is possible to use different open source and commercial optimizers for the optimization process. We use the open-source GLPK package ( GNU Linear Programming Kit ). GLPK allows solving large-scale linear programming, mixed-integer programming, and other problems. The script utilizes GraphQL queries to the meta subgraph to retrieve the relevant information for the allocation optimization (current allocations, network information, etc.). Furthermore, open APIs are used to retrieve price data for the GRT token, ETH, and fiat currencies, as well as to get the current gas price. An ssh tunnel to the indexer graph node and the database server is used to gather information about the subgraph sync statuses and the latest valid POI for broken subgraphs. RPC calls to ethereum nodes are used to call the rewards manager contract to get the pending rewards per subgraph. The data preprocessing, manipulation and preparation are performed using pandas . The allocation optimization script can be executed either in the command line or as a web application. Web Application \u00b6 The web application is based on streamlit. Streamlit is a python package that allows the development of data-driven applications. Visual charts are also displayed in this web interface using plotly . The web application takes the core logic from the optimizer.py file and displays the optimization process in a visual gui. The parameters are supplied via streamlit objects (checkboxes, sliders...) which are defined in the ./src/webapp/sidebar.py file. The visualization of the optimization process is implemented in ./src/webapp/display_optimizer.py . This includes functions to display further subgraph information, charts and data tables for the current optimization run. Further metrics, such as price metrics, the DIY chart builder, and historical performance charts are implemented in ./src/webapp/key_metrics.py . Optimization Data \u00b6 The optimization runs are logged in a json file called \"optimizer_log.json\". It is located in the subdirectory ./data/ . Each optimization run is sasved as a key value pair. Each runs key is the datetime of the run. Following metrics and data points are stored: * Parameters: for the run * Price data : gas price, grt-usd, eth-usd, grt-eth * Network data: total indexing rewards, grt_issuance ... * Indexer data: total stake, total allocated tokens * Indexer's current allocations: Saved as a key-value pair with the subgraph ipfs hash as key * Current rewards: hourly, daily, weekly, yearly * Optimizer run data: Threshold reached/not reached, which subgraphs to allocate to, expected returns... Example: { \"2021-09-06-10:43\": { \"datetime\": \"2021-09-06-10:43\", \"parameters\": { \"indexer_id\": \"0x453B5E165Cf98FF60167cCd3560EBf8D436ca86C\", \"blacklist\": false, \"parallel_allocations\": 1, \"max_percentage\": 0.05, \"threshold\": 20, \"subgraph_list_parameter\": false, \"threshold_interval\": \"weekly\", \"reserve_stake\": 500, \"min_allocation\": 0, \"min_signalled_grt_subgraph\": 100, \"min_allocated_grt_subgraph\": 100, \"app\": \"web\", \"slack_alerting\": false }, \"price_data\": { \"gas_price_gwei\": 105.928445249, \"allocation_gas_usage\": 270000, \"ETH-USD\": 3951.26, \"GRT-USD\": 1.04, \"GRT-ETH\": 0.00026276 }, \"network_data\": { \"total_indexing_rewards\": 196762472.49785247, \"total_tokens_signalled\": 3315140.590051623, \"total_supply\": 10180362807.536777, \"total_tokens_allocated\": 3105721872.4989176, \"grt_issuance\": 1000000012184945188, \"yearly_inflation_percentage\": 1.0300000002147995 }, \"indexer\": { \"indexer_total_stake\": 2389720.538838383, \"indexer_total_allocated_tokens\": 2389220.55 }, \"current_allocations\": { \"QmRavjdwiaU7mFWT7Uum28Lf6y6cm397z6CdZPpLcFj9iR\": { \"Address\": \"0x303b502eba6fc9009263db01c6f1edeabe6427bb40a7e2e9be65f60760e5bb12\", \"Name_x\": \"Bot Bait v2\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x0505dc13c2440fc7ecfbdd8fb4576e47948cff17\", \"Name_y\": \"Bot Bait v2\", \"signalledTokensTotal\": 3412.8412500000004, \"stakedTokensTotal\": 1697163.1099999999, \"indexing_reward_hourly\": 10.107526298208883, \"indexing_reward_daily\": 242.58237063492135, \"indexing_reward_weekly\": 1698.0754347925108, \"indexing_reward_yearly\": 88542.58093704746, \"pending_rewards\": 3884.652857838089 }, \"QmT2McMyDQe5eVQJDESAXGygGU3yguwdREaLvq7ahGZiQ1\": { \"Address\": \"0x459aa5684fa2e9ce27420af9018f0317d9a58fd9e8d36bc065b6eebf7f546d2a\", \"Name_x\": \"dot-crypto-registry\", \"Allocation\": 477444.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x07d048e19dd31c73777423bcb10a20f1b450d962\", \"Name_y\": \"dot-crypto-registry\", \"signalledTokensTotal\": 7668.932316167791, \"stakedTokensTotal\": 5501770.109999999, \"indexing_reward_hourly\": 6.998907718194807, \"indexing_reward_daily\": 167.974989729743, \"indexing_reward_weekly\": 1175.8241251128225, \"indexing_reward_yearly\": 61310.8820917938, \"pending_rewards\": 2896.8974332849807 }, \"QmU4yY98kYV4GUHJDYvpnrD9fqyB7HmvrTfq5KosWh8Lrh\": { \"Address\": \"0x55221e21ce7e608a8931f43a1704122501c58837cbb9aac6fdbb81bf4b507f26\", \"Name_x\": \"fei\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x547529b3fb503854cf2cc3b69b95e0b673d38d3b\", \"Name_y\": \"fei\", \"signalledTokensTotal\": 1924.339946715805, \"stakedTokensTotal\": 997944.11, \"indexing_reward_hourly\": 9.692324634960048, \"indexing_reward_daily\": 232.61745926186728, \"indexing_reward_weekly\": 1628.3211028178537, \"indexing_reward_yearly\": 84905.387642787, \"pending_rewards\": 3724.8364730953094 }, \"QmR6Sv5TPHktkK98GqZt4dhLNQ81CzXpASaqsibAxewv57\": { \"Address\": \"0x28ef98296776cf391293841a8f8a838cea705599b33d95dbd333049c631478c2\", \"Name_x\": \"makerdao-governance\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x93721ba038d1317464ebe2c9cf0dd4f569bae523\", \"Name_y\": \"makerdao-governance\", \"signalledTokensTotal\": 2215.506462674542, \"stakedTokensTotal\": 1479250.1099999999, \"indexing_reward_hourly\": 7.528072394411027, \"indexing_reward_daily\": 180.67503302674024, \"indexing_reward_weekly\": 1264.7243674799313, \"indexing_reward_yearly\": 65946.39871480808, \"pending_rewards\": 3297.482606101014 }, \"QmPXtp2UdoDsoryngUEMTsy1nPbVMuVrgozCMwyZjXUS8N\": { \"Address\": \"0x11bd056572a84f4f2700896fcd3a7434947cdb5a768ec4028f7935cd2cc2c687\", \"Name_x\": \"Totle Swap\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0xcd39d994f0a7e22d24028e597041e1707a4a623a\", \"Name_y\": \"Totle Swap\", \"signalledTokensTotal\": 1950.003419570772, \"stakedTokensTotal\": 1265417.11, \"indexing_reward_hourly\": 7.745581829774142, \"indexing_reward_daily\": 185.89529690823989, \"indexing_reward_weekly\": 1301.2661896952388, \"indexing_reward_yearly\": 67851.7953684505, \"pending_rewards\": 3402.7965587005338 } }, \"current_rewards\": { \"indexing_reward_hourly\": 42.072412875548906, \"indexing_reward_daily\": 1009.7451495615118, \"indexing_reward_weekly\": 7068.211219898357, \"indexing_reward_yearly\": 368557.0447548868 }, \"optimizer\": { \"grt_per_allocation\": 119461.02694191915, \"allocations_total\": 20.0, \"stake_to_allocate\": 2389220.538838383, \"optimized_allocations\": { \"QmNNqS4Ftof3kGrTGrpynFYgeK5R6vVTEqADSN63vXEKC8\": { \"allocation_amount\": 119486.026941919, \"name\": \"Umbria\", \"address\": \"0x008f49562d4bdb43ae1b4b68097952d174fcec525019b0d270d2fe533a047d15\", \"signal_stake_ratio\": 0.0019853511385943645 }, \"QmNukFUkc6DspWQx8ZzRSvbpsBWaiPirQdbYPq6Qc4B4Wi\": { \"allocation_amount\": 119486.026941919, \"name\": \"Dummy Subgraph 1\", \"address\": \"0x087a6e8c03e01c5f29767e57ff2dd0ea619de26c46841ce4cf952e1c9cd64c07\", \"signal_stake_ratio\": 0.0021272326548612175 }, \"QmNyuWjzFxSaX9c9WCpWqVYYEo1TCtvfsL9gcqmhx7ArHy\": { \"allocation_amount\": 119486.026941919, \"name\": \"Bot Bait v1\", \"address\": \"0x098b3a9b9cb4299e66510822a1ce0c106c145a5724531509c3967077f659b8e4\", \"signal_stake_ratio\": 0.0018682955005493798 }, \"QmP7ZmWYHN9CTVZyEQ6zu1kuaJgi2AreAw3zFRjbgA5oMS\": { \"allocation_amount\": 119486.026941919, \"name\": \"Ribbon Finance\", \"address\": \"0x0b818c9b0a4eae4b7c2322636df77ce458ed9ff5e120a3d91524c66d1046f029\", \"signal_stake_ratio\": 0.001792860095725464 }, \"QmPU2gPVfovDGxDHt8FpXbhbxPq3dWNT6cNd9xqZYcD7uA\": { \"allocation_amount\": 119486.026941919, \"name\": \"elyfi\", \"address\": \"0x10bf983634fabedf30199c6c9c8960162a3b182ee8be3a7a4561e904bcbd0b19\", \"signal_stake_ratio\": 0.002041595065280313 }, \"QmPVjCWWZeaN7Mw5P6GEhbGixFbv8XKvqTa1oTv7RQsosM\": { \"allocation_amount\": 119486.026941919, \"name\": \"uniswap-v2-tokenHourData-subgraph\", \"address\": \"0x112efda0d0c6f9d853f3e0e5f7bc789003efbff0603c573fea0d79e63acc5720\", \"signal_stake_ratio\": 0.0019880954256876657 }, \"QmPdejzo2ENKgPxBFUh6KJ66YVFnYxmmxXpZpMoAzyL2dY\": { \"allocation_amount\": 119486.026941919, \"name\": \"Subgraph 21-QmPdejzo2ENKgPxBFUh6KJ66YVFnYxmmxXpZpMoAzyL2dY\", \"address\": \"0x133698f83f7ab5e98d36fb55f70ea4ceb121f284434bc232db1083e7a2067fc3\", \"signal_stake_ratio\": 0.002045514850608105 }, \"QmPhfSkFPbooXNJUMcQSWjMXoJYF3GnWT4JmHkxYXA85Zz\": { \"allocation_amount\": 119486.026941919, \"name\": \"Bancor\", \"address\": \"0x143db715c25f1e97631fd370a1db89108baace5ae71366da39fa44136b3567b1\", \"signal_stake_ratio\": 0.001668356507081701 }, \"QmQQeCUjemEf6urSR5SUvvdRTn9ZXdctHwuxjPJoFJD6wR\": { \"allocation_amount\": 119486.026941919, \"name\": \"renft\", \"address\": \"0x1ebd1e97a93bc8864e26088336ddd6b4e6f2bdc760ee1e29b3a9766921527cb8\", \"signal_stake_ratio\": 0.0020115677900367354 }, \"QmQXc8NHJ9ZbFkWBBJLiQtLuHBaVZtqaBy2cvm7VchULAM\": { \"allocation_amount\": 119486.026941919, \"name\": \"NFT Analytics BAYC\", \"address\": \"0x2085d7f6c1fcbfedff08446dc68104fd93f90f36d8247f217b6ead7983756d62\", \"signal_stake_ratio\": 0.0017770638165785454 }, \"QmQj3DDJzo9mS9m7bHriw8XdnU3od65HSThebeeDBQiujP\": { \"allocation_amount\": 119486.026941919, \"name\": \"Wrapped ETH\", \"address\": \"0x23739834f69676e56923f399b360beaf32cb222b1871dc85000ac7839b1c8682\", \"signal_stake_ratio\": 0.0029928953473274764 }, \"QmRWuFqUhuiggfSaSUsk4Z3BvZHwuwn66xw92k2fpNC2gF\": { \"allocation_amount\": 119486.026941919, \"name\": \"PAX\", \"address\": \"0x2f33513a1eafee12fd3f75bbe0c6a25348a74887b1e566f911e8cc55a04b9d70\", \"signal_stake_ratio\": 0.002122135597897978 }, \"QmRavjdwiaU7mFWT7Uum28Lf6y6cm397z6CdZPpLcFj9iR\": { \"allocation_amount\": 119486.026941919, \"name\": \"Bot Bait v2\", \"address\": \"0x303b502eba6fc9009263db01c6f1edeabe6427bb40a7e2e9be65f60760e5bb12\", \"signal_stake_ratio\": 0.0018786721923364576 }, \"QmRrHfw1Y1EZKUxd5MGTgmnbqf4hf8nynBG5F3ZQyjtVoF\": { \"allocation_amount\": 118986.026941918, \"name\": \"burny-boys\", \"address\": \"0x342ab2a85b6fe158b76f900e2c13c0aaef70c6c3671616046e0dfd0cd48345c2\", \"signal_stake_ratio\": 0.0016565223849501901 }, \"QmS7VGsn5s8UTMrebMRVNub2qCBYK19Qvg4dGNdTqsHX4k\": { \"allocation_amount\": 119486.026941919, \"name\": \"Test remove soon\", \"address\": \"0x380f876c05b7fce7bd8234de974bf0d5a0b262f7325bdb1a785ce4a120691831\", \"signal_stake_ratio\": 0.0020431821109430093 }, \"QmSjSH4EQHRNVbwGSkcEGQzDDRsBSmiDF4z63DMthsXf1M\": { \"allocation_amount\": 119486.026941919, \"name\": \"wildcards.world\", \"address\": \"0x41450cad731320fa6a709883e20bb2f8c6647e5b4937e7e59e0ed1373fa26efc\", \"signal_stake_ratio\": 0.0017377616680302067 }, \"QmSz8pavvfKeXXkSYsE5HH7UhD4LTKZ6szvnNohss5kxQz\": { \"allocation_amount\": 119486.026941919, \"name\": \"Keep network\", \"address\": \"0x4509060e1d1548bfd381baeacdadf0c163788e9dc472de48f523dbc4452742e3\", \"signal_stake_ratio\": 0.0017188725044591292 }, \"QmTKsqg2wUwsuGkeEnyKY1iPMdyaMXDhtCgtHeAxAe4X9r\": { \"allocation_amount\": 119486.026941919, \"name\": \"Cryptokitties\", \"address\": \"0x4a17b3535a7c534b1e65054a2cf8997ad7b76f3d56e9d3457ec09a75894ccfe1\", \"signal_stake_ratio\": 0.002076849714983104 }, \"QmU3MkEQCHCJbZ5U6sJbifpNLKwehSnYRgSGbeNUyY8Kb2\": { \"allocation_amount\": 119486.026941919, \"name\": \"Tacoswap Vision\", \"address\": \"0x54b81138d236538ce5098b45a63598cb6cc68f791fc67b239b63329db47b2d85\", \"signal_stake_ratio\": 0.002465065297595677 }, \"QmU4yY98kYV4GUHJDYvpnrD9fqyB7HmvrTfq5KosWh8Lrh\": { \"allocation_amount\": 119486.026941919, \"name\": \"fei\", \"address\": \"0x55221e21ce7e608a8931f43a1704122501c58837cbb9aac6fdbb81bf4b507f26\", \"signal_stake_ratio\": 0.0017221506176195688 }, \"indexingRewardHour\": 49.90333067781851, \"indexingRewardDay\": 1197.679936267644, \"indexingRewardWeek\": 8383.752663117895, \"indexingRewardYear\": 437153.17673769005 }, \"gas_costs_allocating_eth\": 0.028600680217230005, \"gas_costs_parallel_allocation_new_close_eth\": 1.1440272086892003, \"gas_costs_parallel_allocation_new_close_usd\": 4520.3489486052895, \"gas_costs_parallel_allocation_new_close_grt\": 4353.886469360634, \"increase_rewards_percentage\": -42.99, \"increase_rewards_fiat\": -3159.88, \"increase_rewards_grt\": -3038.35, \"threshold_reached\": false } } },","title":"Architecture"},{"location":"5.%20Architecture/#architecture","text":"The tech stack for the allocation optimization tool contains different libraries as well as tools. The used programming language is python . Let's start with the Allocation Optimization Script itself. This core module of the application contains the relevant steps to optimize the allocations so that the highest indexing rewards can be achieved according to the given parameters.","title":"Architecture"},{"location":"5.%20Architecture/#core-functionality","text":"The script is based on the Pyomo . optimization modeling language, which is based on Python and is open source. With the help of Pyomo, it is possible to use different open source and commercial optimizers for the optimization process. We use the open-source GLPK package ( GNU Linear Programming Kit ). GLPK allows solving large-scale linear programming, mixed-integer programming, and other problems. The script utilizes GraphQL queries to the meta subgraph to retrieve the relevant information for the allocation optimization (current allocations, network information, etc.). Furthermore, open APIs are used to retrieve price data for the GRT token, ETH, and fiat currencies, as well as to get the current gas price. An ssh tunnel to the indexer graph node and the database server is used to gather information about the subgraph sync statuses and the latest valid POI for broken subgraphs. RPC calls to ethereum nodes are used to call the rewards manager contract to get the pending rewards per subgraph. The data preprocessing, manipulation and preparation are performed using pandas . The allocation optimization script can be executed either in the command line or as a web application.","title":"Core Functionality"},{"location":"5.%20Architecture/#web-application","text":"The web application is based on streamlit. Streamlit is a python package that allows the development of data-driven applications. Visual charts are also displayed in this web interface using plotly . The web application takes the core logic from the optimizer.py file and displays the optimization process in a visual gui. The parameters are supplied via streamlit objects (checkboxes, sliders...) which are defined in the ./src/webapp/sidebar.py file. The visualization of the optimization process is implemented in ./src/webapp/display_optimizer.py . This includes functions to display further subgraph information, charts and data tables for the current optimization run. Further metrics, such as price metrics, the DIY chart builder, and historical performance charts are implemented in ./src/webapp/key_metrics.py .","title":"Web Application"},{"location":"5.%20Architecture/#optimization-data","text":"The optimization runs are logged in a json file called \"optimizer_log.json\". It is located in the subdirectory ./data/ . Each optimization run is sasved as a key value pair. Each runs key is the datetime of the run. Following metrics and data points are stored: * Parameters: for the run * Price data : gas price, grt-usd, eth-usd, grt-eth * Network data: total indexing rewards, grt_issuance ... * Indexer data: total stake, total allocated tokens * Indexer's current allocations: Saved as a key-value pair with the subgraph ipfs hash as key * Current rewards: hourly, daily, weekly, yearly * Optimizer run data: Threshold reached/not reached, which subgraphs to allocate to, expected returns... Example: { \"2021-09-06-10:43\": { \"datetime\": \"2021-09-06-10:43\", \"parameters\": { \"indexer_id\": \"0x453B5E165Cf98FF60167cCd3560EBf8D436ca86C\", \"blacklist\": false, \"parallel_allocations\": 1, \"max_percentage\": 0.05, \"threshold\": 20, \"subgraph_list_parameter\": false, \"threshold_interval\": \"weekly\", \"reserve_stake\": 500, \"min_allocation\": 0, \"min_signalled_grt_subgraph\": 100, \"min_allocated_grt_subgraph\": 100, \"app\": \"web\", \"slack_alerting\": false }, \"price_data\": { \"gas_price_gwei\": 105.928445249, \"allocation_gas_usage\": 270000, \"ETH-USD\": 3951.26, \"GRT-USD\": 1.04, \"GRT-ETH\": 0.00026276 }, \"network_data\": { \"total_indexing_rewards\": 196762472.49785247, \"total_tokens_signalled\": 3315140.590051623, \"total_supply\": 10180362807.536777, \"total_tokens_allocated\": 3105721872.4989176, \"grt_issuance\": 1000000012184945188, \"yearly_inflation_percentage\": 1.0300000002147995 }, \"indexer\": { \"indexer_total_stake\": 2389720.538838383, \"indexer_total_allocated_tokens\": 2389220.55 }, \"current_allocations\": { \"QmRavjdwiaU7mFWT7Uum28Lf6y6cm397z6CdZPpLcFj9iR\": { \"Address\": \"0x303b502eba6fc9009263db01c6f1edeabe6427bb40a7e2e9be65f60760e5bb12\", \"Name_x\": \"Bot Bait v2\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x0505dc13c2440fc7ecfbdd8fb4576e47948cff17\", \"Name_y\": \"Bot Bait v2\", \"signalledTokensTotal\": 3412.8412500000004, \"stakedTokensTotal\": 1697163.1099999999, \"indexing_reward_hourly\": 10.107526298208883, \"indexing_reward_daily\": 242.58237063492135, \"indexing_reward_weekly\": 1698.0754347925108, \"indexing_reward_yearly\": 88542.58093704746, \"pending_rewards\": 3884.652857838089 }, \"QmT2McMyDQe5eVQJDESAXGygGU3yguwdREaLvq7ahGZiQ1\": { \"Address\": \"0x459aa5684fa2e9ce27420af9018f0317d9a58fd9e8d36bc065b6eebf7f546d2a\", \"Name_x\": \"dot-crypto-registry\", \"Allocation\": 477444.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x07d048e19dd31c73777423bcb10a20f1b450d962\", \"Name_y\": \"dot-crypto-registry\", \"signalledTokensTotal\": 7668.932316167791, \"stakedTokensTotal\": 5501770.109999999, \"indexing_reward_hourly\": 6.998907718194807, \"indexing_reward_daily\": 167.974989729743, \"indexing_reward_weekly\": 1175.8241251128225, \"indexing_reward_yearly\": 61310.8820917938, \"pending_rewards\": 2896.8974332849807 }, \"QmU4yY98kYV4GUHJDYvpnrD9fqyB7HmvrTfq5KosWh8Lrh\": { \"Address\": \"0x55221e21ce7e608a8931f43a1704122501c58837cbb9aac6fdbb81bf4b507f26\", \"Name_x\": \"fei\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x547529b3fb503854cf2cc3b69b95e0b673d38d3b\", \"Name_y\": \"fei\", \"signalledTokensTotal\": 1924.339946715805, \"stakedTokensTotal\": 997944.11, \"indexing_reward_hourly\": 9.692324634960048, \"indexing_reward_daily\": 232.61745926186728, \"indexing_reward_weekly\": 1628.3211028178537, \"indexing_reward_yearly\": 84905.387642787, \"pending_rewards\": 3724.8364730953094 }, \"QmR6Sv5TPHktkK98GqZt4dhLNQ81CzXpASaqsibAxewv57\": { \"Address\": \"0x28ef98296776cf391293841a8f8a838cea705599b33d95dbd333049c631478c2\", \"Name_x\": \"makerdao-governance\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0x93721ba038d1317464ebe2c9cf0dd4f569bae523\", \"Name_y\": \"makerdao-governance\", \"signalledTokensTotal\": 2215.506462674542, \"stakedTokensTotal\": 1479250.1099999999, \"indexing_reward_hourly\": 7.528072394411027, \"indexing_reward_daily\": 180.67503302674024, \"indexing_reward_weekly\": 1264.7243674799313, \"indexing_reward_yearly\": 65946.39871480808, \"pending_rewards\": 3297.482606101014 }, \"QmPXtp2UdoDsoryngUEMTsy1nPbVMuVrgozCMwyZjXUS8N\": { \"Address\": \"0x11bd056572a84f4f2700896fcd3a7434947cdb5a768ec4028f7935cd2cc2c687\", \"Name_x\": \"Totle Swap\", \"Allocation\": 477944.11000000004, \"IndexingReward\": 0.0, \"allocation_id\": \"0xcd39d994f0a7e22d24028e597041e1707a4a623a\", \"Name_y\": \"Totle Swap\", \"signalledTokensTotal\": 1950.003419570772, \"stakedTokensTotal\": 1265417.11, \"indexing_reward_hourly\": 7.745581829774142, \"indexing_reward_daily\": 185.89529690823989, \"indexing_reward_weekly\": 1301.2661896952388, \"indexing_reward_yearly\": 67851.7953684505, \"pending_rewards\": 3402.7965587005338 } }, \"current_rewards\": { \"indexing_reward_hourly\": 42.072412875548906, \"indexing_reward_daily\": 1009.7451495615118, \"indexing_reward_weekly\": 7068.211219898357, \"indexing_reward_yearly\": 368557.0447548868 }, \"optimizer\": { \"grt_per_allocation\": 119461.02694191915, \"allocations_total\": 20.0, \"stake_to_allocate\": 2389220.538838383, \"optimized_allocations\": { \"QmNNqS4Ftof3kGrTGrpynFYgeK5R6vVTEqADSN63vXEKC8\": { \"allocation_amount\": 119486.026941919, \"name\": \"Umbria\", \"address\": \"0x008f49562d4bdb43ae1b4b68097952d174fcec525019b0d270d2fe533a047d15\", \"signal_stake_ratio\": 0.0019853511385943645 }, \"QmNukFUkc6DspWQx8ZzRSvbpsBWaiPirQdbYPq6Qc4B4Wi\": { \"allocation_amount\": 119486.026941919, \"name\": \"Dummy Subgraph 1\", \"address\": \"0x087a6e8c03e01c5f29767e57ff2dd0ea619de26c46841ce4cf952e1c9cd64c07\", \"signal_stake_ratio\": 0.0021272326548612175 }, \"QmNyuWjzFxSaX9c9WCpWqVYYEo1TCtvfsL9gcqmhx7ArHy\": { \"allocation_amount\": 119486.026941919, \"name\": \"Bot Bait v1\", \"address\": \"0x098b3a9b9cb4299e66510822a1ce0c106c145a5724531509c3967077f659b8e4\", \"signal_stake_ratio\": 0.0018682955005493798 }, \"QmP7ZmWYHN9CTVZyEQ6zu1kuaJgi2AreAw3zFRjbgA5oMS\": { \"allocation_amount\": 119486.026941919, \"name\": \"Ribbon Finance\", \"address\": \"0x0b818c9b0a4eae4b7c2322636df77ce458ed9ff5e120a3d91524c66d1046f029\", \"signal_stake_ratio\": 0.001792860095725464 }, \"QmPU2gPVfovDGxDHt8FpXbhbxPq3dWNT6cNd9xqZYcD7uA\": { \"allocation_amount\": 119486.026941919, \"name\": \"elyfi\", \"address\": \"0x10bf983634fabedf30199c6c9c8960162a3b182ee8be3a7a4561e904bcbd0b19\", \"signal_stake_ratio\": 0.002041595065280313 }, \"QmPVjCWWZeaN7Mw5P6GEhbGixFbv8XKvqTa1oTv7RQsosM\": { \"allocation_amount\": 119486.026941919, \"name\": \"uniswap-v2-tokenHourData-subgraph\", \"address\": \"0x112efda0d0c6f9d853f3e0e5f7bc789003efbff0603c573fea0d79e63acc5720\", \"signal_stake_ratio\": 0.0019880954256876657 }, \"QmPdejzo2ENKgPxBFUh6KJ66YVFnYxmmxXpZpMoAzyL2dY\": { \"allocation_amount\": 119486.026941919, \"name\": \"Subgraph 21-QmPdejzo2ENKgPxBFUh6KJ66YVFnYxmmxXpZpMoAzyL2dY\", \"address\": \"0x133698f83f7ab5e98d36fb55f70ea4ceb121f284434bc232db1083e7a2067fc3\", \"signal_stake_ratio\": 0.002045514850608105 }, \"QmPhfSkFPbooXNJUMcQSWjMXoJYF3GnWT4JmHkxYXA85Zz\": { \"allocation_amount\": 119486.026941919, \"name\": \"Bancor\", \"address\": \"0x143db715c25f1e97631fd370a1db89108baace5ae71366da39fa44136b3567b1\", \"signal_stake_ratio\": 0.001668356507081701 }, \"QmQQeCUjemEf6urSR5SUvvdRTn9ZXdctHwuxjPJoFJD6wR\": { \"allocation_amount\": 119486.026941919, \"name\": \"renft\", \"address\": \"0x1ebd1e97a93bc8864e26088336ddd6b4e6f2bdc760ee1e29b3a9766921527cb8\", \"signal_stake_ratio\": 0.0020115677900367354 }, \"QmQXc8NHJ9ZbFkWBBJLiQtLuHBaVZtqaBy2cvm7VchULAM\": { \"allocation_amount\": 119486.026941919, \"name\": \"NFT Analytics BAYC\", \"address\": \"0x2085d7f6c1fcbfedff08446dc68104fd93f90f36d8247f217b6ead7983756d62\", \"signal_stake_ratio\": 0.0017770638165785454 }, \"QmQj3DDJzo9mS9m7bHriw8XdnU3od65HSThebeeDBQiujP\": { \"allocation_amount\": 119486.026941919, \"name\": \"Wrapped ETH\", \"address\": \"0x23739834f69676e56923f399b360beaf32cb222b1871dc85000ac7839b1c8682\", \"signal_stake_ratio\": 0.0029928953473274764 }, \"QmRWuFqUhuiggfSaSUsk4Z3BvZHwuwn66xw92k2fpNC2gF\": { \"allocation_amount\": 119486.026941919, \"name\": \"PAX\", \"address\": \"0x2f33513a1eafee12fd3f75bbe0c6a25348a74887b1e566f911e8cc55a04b9d70\", \"signal_stake_ratio\": 0.002122135597897978 }, \"QmRavjdwiaU7mFWT7Uum28Lf6y6cm397z6CdZPpLcFj9iR\": { \"allocation_amount\": 119486.026941919, \"name\": \"Bot Bait v2\", \"address\": \"0x303b502eba6fc9009263db01c6f1edeabe6427bb40a7e2e9be65f60760e5bb12\", \"signal_stake_ratio\": 0.0018786721923364576 }, \"QmRrHfw1Y1EZKUxd5MGTgmnbqf4hf8nynBG5F3ZQyjtVoF\": { \"allocation_amount\": 118986.026941918, \"name\": \"burny-boys\", \"address\": \"0x342ab2a85b6fe158b76f900e2c13c0aaef70c6c3671616046e0dfd0cd48345c2\", \"signal_stake_ratio\": 0.0016565223849501901 }, \"QmS7VGsn5s8UTMrebMRVNub2qCBYK19Qvg4dGNdTqsHX4k\": { \"allocation_amount\": 119486.026941919, \"name\": \"Test remove soon\", \"address\": \"0x380f876c05b7fce7bd8234de974bf0d5a0b262f7325bdb1a785ce4a120691831\", \"signal_stake_ratio\": 0.0020431821109430093 }, \"QmSjSH4EQHRNVbwGSkcEGQzDDRsBSmiDF4z63DMthsXf1M\": { \"allocation_amount\": 119486.026941919, \"name\": \"wildcards.world\", \"address\": \"0x41450cad731320fa6a709883e20bb2f8c6647e5b4937e7e59e0ed1373fa26efc\", \"signal_stake_ratio\": 0.0017377616680302067 }, \"QmSz8pavvfKeXXkSYsE5HH7UhD4LTKZ6szvnNohss5kxQz\": { \"allocation_amount\": 119486.026941919, \"name\": \"Keep network\", \"address\": \"0x4509060e1d1548bfd381baeacdadf0c163788e9dc472de48f523dbc4452742e3\", \"signal_stake_ratio\": 0.0017188725044591292 }, \"QmTKsqg2wUwsuGkeEnyKY1iPMdyaMXDhtCgtHeAxAe4X9r\": { \"allocation_amount\": 119486.026941919, \"name\": \"Cryptokitties\", \"address\": \"0x4a17b3535a7c534b1e65054a2cf8997ad7b76f3d56e9d3457ec09a75894ccfe1\", \"signal_stake_ratio\": 0.002076849714983104 }, \"QmU3MkEQCHCJbZ5U6sJbifpNLKwehSnYRgSGbeNUyY8Kb2\": { \"allocation_amount\": 119486.026941919, \"name\": \"Tacoswap Vision\", \"address\": \"0x54b81138d236538ce5098b45a63598cb6cc68f791fc67b239b63329db47b2d85\", \"signal_stake_ratio\": 0.002465065297595677 }, \"QmU4yY98kYV4GUHJDYvpnrD9fqyB7HmvrTfq5KosWh8Lrh\": { \"allocation_amount\": 119486.026941919, \"name\": \"fei\", \"address\": \"0x55221e21ce7e608a8931f43a1704122501c58837cbb9aac6fdbb81bf4b507f26\", \"signal_stake_ratio\": 0.0017221506176195688 }, \"indexingRewardHour\": 49.90333067781851, \"indexingRewardDay\": 1197.679936267644, \"indexingRewardWeek\": 8383.752663117895, \"indexingRewardYear\": 437153.17673769005 }, \"gas_costs_allocating_eth\": 0.028600680217230005, \"gas_costs_parallel_allocation_new_close_eth\": 1.1440272086892003, \"gas_costs_parallel_allocation_new_close_usd\": 4520.3489486052895, \"gas_costs_parallel_allocation_new_close_grt\": 4353.886469360634, \"increase_rewards_percentage\": -42.99, \"increase_rewards_fiat\": -3159.88, \"increase_rewards_grt\": -3038.35, \"threshold_reached\": false } } },","title":"Optimization Data"},{"location":"6.%20Developer/","text":"Developer Documentation \u00b6 Functioning \u00b6 First we grab all necessary The Graph data with a GraphQL Query to \" https://gateway.network.thegraph.com/network \" . Here we define a variable input for the indexer id. This has to be supplied via the parameter indexer_id. The query is defined in ./src/queries.py as the function getDataAllocationOptimizer() def getDataAllocationOptimizer(indexer_id, variables=None, ): \"\"\" Grabs all relevant Data from the Mainnet Meta Subgraph which are used for the Optimizer Parameter ------- indexer_id : Address of Indexer to get the Data From Returns ------- Dict with Subgraph Data (All Subgraphs with Name, SignalledTokens, Stakedtokens, Id), Indexer Data (Allocated Tokens Total and all Allocations), Graph Network Data (Total Tokens Allocated, total TokensStaked, Total Supply, GRT Issurance) \"\"\" load_dotenv() API_GATEWAY = os.getenv('API_GATEWAY') OPTIMIZATION_DATA = \"\"\" query MyQuery($input: String){ subgraphDeployments { originalName signalledTokens stakedTokens id } indexer(id: $input) { tokenCapacity allocatedTokens stakedTokens allocations { allocatedTokens id subgraphDeployment { originalName id } indexingRewards } account { defaultName { name } } } graphNetworks { totalTokensAllocated totalTokensStaked totalIndexingRewards totalTokensSignalled totalSupply networkGRTIssuance } } \"\"\" variables = {'input': indexer_id} request_json = {'query': OPTIMIZATION_DATA} if indexer_id: request_json['variables'] = variables resp = requests.post(API_GATEWAY, json=request_json) data = json.loads(resp.text) data = data['data'] return data Furthermore we have to obtain price data with the functions getFiatPrice() and getGasPrice() . We obtain fiat prices via the coingecko API. For the current gas price in gwei we use the Anyblock Analytics gas price API. Then we use the optimizeAllocations() function in ./src/optimizer.py to run the optimization process. This function logs all relevant data for the allocation run in a variable called optimizer_results which is later translated to json and appended to ./data/optimizer_log.json . If the blacklist paramter is set to True , createBlacklist from ./src/subgraph_health_checks.py is run. This populates the blacklist in the config.json. After grabbing the relevant data (price data, network data from the network subgraph) all indexing rewards (hourly,daily,weekly and yearly) are calculated for the currently open allocations. Furthermore the pending rewards for the open allocations are obtained via rpc calls to the reward manager contract . All relevant data is appended to the variable data which is used for the optimization process. This dictionary includes key-value pairs, where the key is the subgraph and the value includes informations such as signalledTokensTotal and stakedTokensTotal. # nested dictionary stored in data, key is SubgraphName,Address,ID data = {(df.reset_index()['Name_y'].values[j], df.reset_index()['Address'].values[j], df['id'].values[j]): { 'Allocation': df['Allocation'].values[j], 'signalledTokensTotal': df['signalledTokensTotal'].values[j], 'stakedTokensTotal': df['stakedTokensTotal'].values[j], 'SignalledNetwork': int(total_tokens_signalled) / 10 ** 18, 'indexingRewardYear': indexing_reward_year, 'indexingRewardWeek': indexing_reward_week, 'indexingRewardDay': indexing_reward_day, 'indexingRewardHour': indexing_reward_hour, 'id': df['id'].values[j]} for j in set_J} The optimization is run for every reward interval (Hourly, Daily, Weekly and Yearly). The objective of the optimization algorithm is to maximize the Indexing Rewards. Therefore it has to maximize the summation of the indexing reward formula. # The Variable (Allocations) that should be changed to optimize rewards model.x = pyomo.Var(C, domain=pyomo.NonNegativeReals) # formula and model model.rewards = pyomo.Objective( expr=sum((model.x[c] / (data[c]['stakedTokensTotal'] + sliced_stake)) * ( data[c]['signalledTokensTotal'] / data[c]['SignalledNetwork']) * data[c][reward_interval] for c in C), # Indexing Rewards Formula (Daily Rewards) sense=pyomo.maximize) # maximize Indexing Rewards # set constraint that allocations shouldn't be higher than total stake- reserce stake model.vol = pyomo.Constraint(expr=indexer_total_stake - reserve_stake >= sum( model.x[c] for c in C)) model.bound_x = pyomo.ConstraintList() # iterate through subgraphs and set constraints for c in C: # Allocations per Subgraph should be higher than min_allocation model.bound_x.add(model.x[c] >= min_allocation) # Allocation per Subgraph can't be higher than x % of total Allocations model.bound_x.add(model.x[c] <= max_percentage * indexer_total_stake) # set solver to glpk -> In Future this could be changeable solver = pyomo.SolverFactory('glpk') solver.solve(model, keepfiles=True) The variable in this case is model.x[c], this is the variable allocation amount per Subgraph which has to be optimized to generate the maximum indexing reward. The equation takes the allocation per subgraph, the entire allocated stake on the specific subgraph and the signalled tokens on that subgraph into consideration. After the optimization was executed, the optimized rewards weekly / daily are stored in the variables optimized_reward_weekly and optimized_reward_daily . This is used to calculate if the threshold is reached for reallocation. If slack alerting is enabled, the result of the optimization and if the threshold is reached is broadcasted to the desired slack channel. If the threshold is reached, a script.txt and script_never.txt file is created. If the threshold is not reached, these files are not created.","title":"Developer Documentation"},{"location":"6.%20Developer/#developer-documentation","text":"","title":"Developer Documentation"},{"location":"6.%20Developer/#functioning","text":"First we grab all necessary The Graph data with a GraphQL Query to \" https://gateway.network.thegraph.com/network \" . Here we define a variable input for the indexer id. This has to be supplied via the parameter indexer_id. The query is defined in ./src/queries.py as the function getDataAllocationOptimizer() def getDataAllocationOptimizer(indexer_id, variables=None, ): \"\"\" Grabs all relevant Data from the Mainnet Meta Subgraph which are used for the Optimizer Parameter ------- indexer_id : Address of Indexer to get the Data From Returns ------- Dict with Subgraph Data (All Subgraphs with Name, SignalledTokens, Stakedtokens, Id), Indexer Data (Allocated Tokens Total and all Allocations), Graph Network Data (Total Tokens Allocated, total TokensStaked, Total Supply, GRT Issurance) \"\"\" load_dotenv() API_GATEWAY = os.getenv('API_GATEWAY') OPTIMIZATION_DATA = \"\"\" query MyQuery($input: String){ subgraphDeployments { originalName signalledTokens stakedTokens id } indexer(id: $input) { tokenCapacity allocatedTokens stakedTokens allocations { allocatedTokens id subgraphDeployment { originalName id } indexingRewards } account { defaultName { name } } } graphNetworks { totalTokensAllocated totalTokensStaked totalIndexingRewards totalTokensSignalled totalSupply networkGRTIssuance } } \"\"\" variables = {'input': indexer_id} request_json = {'query': OPTIMIZATION_DATA} if indexer_id: request_json['variables'] = variables resp = requests.post(API_GATEWAY, json=request_json) data = json.loads(resp.text) data = data['data'] return data Furthermore we have to obtain price data with the functions getFiatPrice() and getGasPrice() . We obtain fiat prices via the coingecko API. For the current gas price in gwei we use the Anyblock Analytics gas price API. Then we use the optimizeAllocations() function in ./src/optimizer.py to run the optimization process. This function logs all relevant data for the allocation run in a variable called optimizer_results which is later translated to json and appended to ./data/optimizer_log.json . If the blacklist paramter is set to True , createBlacklist from ./src/subgraph_health_checks.py is run. This populates the blacklist in the config.json. After grabbing the relevant data (price data, network data from the network subgraph) all indexing rewards (hourly,daily,weekly and yearly) are calculated for the currently open allocations. Furthermore the pending rewards for the open allocations are obtained via rpc calls to the reward manager contract . All relevant data is appended to the variable data which is used for the optimization process. This dictionary includes key-value pairs, where the key is the subgraph and the value includes informations such as signalledTokensTotal and stakedTokensTotal. # nested dictionary stored in data, key is SubgraphName,Address,ID data = {(df.reset_index()['Name_y'].values[j], df.reset_index()['Address'].values[j], df['id'].values[j]): { 'Allocation': df['Allocation'].values[j], 'signalledTokensTotal': df['signalledTokensTotal'].values[j], 'stakedTokensTotal': df['stakedTokensTotal'].values[j], 'SignalledNetwork': int(total_tokens_signalled) / 10 ** 18, 'indexingRewardYear': indexing_reward_year, 'indexingRewardWeek': indexing_reward_week, 'indexingRewardDay': indexing_reward_day, 'indexingRewardHour': indexing_reward_hour, 'id': df['id'].values[j]} for j in set_J} The optimization is run for every reward interval (Hourly, Daily, Weekly and Yearly). The objective of the optimization algorithm is to maximize the Indexing Rewards. Therefore it has to maximize the summation of the indexing reward formula. # The Variable (Allocations) that should be changed to optimize rewards model.x = pyomo.Var(C, domain=pyomo.NonNegativeReals) # formula and model model.rewards = pyomo.Objective( expr=sum((model.x[c] / (data[c]['stakedTokensTotal'] + sliced_stake)) * ( data[c]['signalledTokensTotal'] / data[c]['SignalledNetwork']) * data[c][reward_interval] for c in C), # Indexing Rewards Formula (Daily Rewards) sense=pyomo.maximize) # maximize Indexing Rewards # set constraint that allocations shouldn't be higher than total stake- reserce stake model.vol = pyomo.Constraint(expr=indexer_total_stake - reserve_stake >= sum( model.x[c] for c in C)) model.bound_x = pyomo.ConstraintList() # iterate through subgraphs and set constraints for c in C: # Allocations per Subgraph should be higher than min_allocation model.bound_x.add(model.x[c] >= min_allocation) # Allocation per Subgraph can't be higher than x % of total Allocations model.bound_x.add(model.x[c] <= max_percentage * indexer_total_stake) # set solver to glpk -> In Future this could be changeable solver = pyomo.SolverFactory('glpk') solver.solve(model, keepfiles=True) The variable in this case is model.x[c], this is the variable allocation amount per Subgraph which has to be optimized to generate the maximum indexing reward. The equation takes the allocation per subgraph, the entire allocated stake on the specific subgraph and the signalled tokens on that subgraph into consideration. After the optimization was executed, the optimized rewards weekly / daily are stored in the variables optimized_reward_weekly and optimized_reward_daily . This is used to calculate if the threshold is reached for reallocation. If slack alerting is enabled, the result of the optimization and if the threshold is reached is broadcasted to the desired slack channel. If the threshold is reached, a script.txt and script_never.txt file is created. If the threshold is not reached, these files are not created.","title":"Functioning"},{"location":"7.%20Caution/","text":"Transparency, Caution and Risk \u26a0\ufe0f\u26d4\ufe0f \u00b6 We are aware that this optimization significantly interferes with the revenues of the respective indexers. This requires a lot of trust. From our side, it is therefore extremely important to bring forth a transparent approach to optimization. Still using this script is at your own risk. ALWAYS check the results of the optimization and check the script.txt if it is suitable for your use-case and setup. Following the script and how it is working will be explained in detail. We purposely created the script in a semi-automatic way, where the results of the optimization process are logged and human intervention is necessary for deploying the changes. In future updates we would like to extend the scope to an automatic optimization script and deploy a hosted version with visualizations (contributions appreciated).","title":"Transparency, Caution and Risk \u26a0\ufe0f\u26d4\ufe0f"},{"location":"7.%20Caution/#transparency-caution-and-risk","text":"We are aware that this optimization significantly interferes with the revenues of the respective indexers. This requires a lot of trust. From our side, it is therefore extremely important to bring forth a transparent approach to optimization. Still using this script is at your own risk. ALWAYS check the results of the optimization and check the script.txt if it is suitable for your use-case and setup. Following the script and how it is working will be explained in detail. We purposely created the script in a semi-automatic way, where the results of the optimization process are logged and human intervention is necessary for deploying the changes. In future updates we would like to extend the scope to an automatic optimization script and deploy a hosted version with visualizations (contributions appreciated).","title":"Transparency, Caution and Risk \u26a0\ufe0f\u26d4\ufe0f"},{"location":"8.%20Changelog/","text":"Changelog \u00b6 Release 1.0.3 beta \ud83c\udf41 \u00b6 Features \u00b6 added \"--ignore_tx_costs\" flag for ignoring gas costs for allocation openings / closings in calculating the threshold Bugfixes \ud83d\udc1e \u00b6 Fixed a couple of bugs regarding df_log, which has a non unique index if there are parallel allocations. Fixed bugs regarding the automatic allocation Enhanced documentation Set automation flag in web application to \"false\" Attention: The automatic allocation flag is now pushed to the main branch. But you should still set it to false or test it on testnet. There could be edge cases which aren't accounted for so far. Release 1.0.2 beta \ud83e\uddea \u00b6 Features \u00b6 Added support for automatic allocations via the indexer agent management endpoint (127.0.0.1:18000/) SetIndexingRules to Never for closing allocations checking if allocations were succesfully closed via web3.py and eventFilters for AllocationClosed SetIndexingRules to always for creating allocations checking if allocations were succesfully created via web3.py and eventFilters for AllocationsCreated Added Selectbox for Streamlit Web App to choose automatic allocations Bugfixes \ud83d\udc1e \u00b6 Allocation Script wasn't gathering all SubgraphDeployments. Now set the limit to 1000 Release 1.0.1 beta \ud83d\udcc8 \u00b6 Features \u00b6 Added support for running the optimization on testnet . Checkout the network parameter in 3. Usage and Parameters.md Added support for testnet optimization in streamlit web application. Refinement and addition of charts for historical performance tracking & GRT performance. Release 1.0 beta \ud83d\udce4 \u00b6 Features \ud83c\udd95 \u00b6 Added subgraph_health_checks.py (optional: SSH tunnel on indexer local database). Allows indexers to fetch subgraphs that have errors, are not in sync, are depreciated or are from blacklisted subgraph developers. These functions, if applied, populate the config.json blacklist element automatically and helps mitigating bot-bait subgraphs. Added automatic blacklisting for blacklisted subgraph developers. If there is a suspicious subgraph developer, the developer can be added to the config.json and the optimization script automatically blacklists all subgraphs released from this address Added automatic blacklisting of inactive (active status: False) subgraphs Added automatic blacklisting of subgraphs with bad health status (errors, not in sync Added further parameters to change the behaviour of the allocation optimization script threshold_interval: Define the interval which is used for calculating the threshold requirment. Currently the recommended threshold interval is \"weekly\". Setting the threshold interval to weekly leads the optimization script to calculate threshold requirments based on weekly indexing rewards. reserve_stake: Enables the indexer to define a dedicated amount of stake which should not be considered in the optimization. This reserve stake will not be allocated! min_allocation: Set the minimum allocation in GRT per subgraph. If this value is above 0, every deployed subgraph will get the minimum allocation amount. ATTENTION \ud83d\udea8: Setting this value above 0 leads to massive increases in transaction costs min_allocated_grt_subgraph: Defines the minimum GRT allocation requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT allocated than the min_allocated_grt_subgraph, then it will not be considered in the optimization process. min_signalled_grt_subgraph: Defines the minimum GRT signal requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT signalled than the min_signalled_grt_subgraph, then it will not be considered in the optimization process. slack_alerting: Enables the user to configure a slack alerting in a dedicated slack channel. Outputs if the optimization reached the threshold and how much increase / decrease in rewards is expected after the optimization. Configure the webhook and channel in the .env file. Refactored the codebase. Now the script isn't bundled in one script.py file. A dedicated src directory is introduced, which also includes a webapp subdirectory for the streamlit application. Included a streamlit-based web application for the optimization. The web application simplifies the usage of the optimization script. Check out the screencast of the web app Implemented historical performance tracking on daily granularity. For closed allocations the indexing rewards are calculated based on the network subgraph data. For active allocations the indexing rewards are calculated by gathering pending rewards data with rpc calls from the reward manager contract . Implemented a DIY Chart builder based on plotly. This is heavy work in progress so expect errors. Added key metrics from previous and current run Abandoned tracking logic with log files for each run. Accumulated metrics of every optimization run in a optimizer_log.json with better structure and key-value pairs. Added a POI fetching script ( poi.py ) to gather the latest acailable POIs for broken / bait subgraphs which are not correctly shown on the indexer agent. Requires a ssh tunnel to the indexer server or has to be run on the indexer server. CAUTION \u26a0\ufe0f: Always crosscheck your POIs before manually closing allocations. If possible always use the indexer CLI Added Naive Method in Optimization Script to keep the ratio of signal / stake on a subgraph. In the model.reward optimization function we added the the part (data[c]['stakedTokensTotal'] + sliced_stake) . This results in better optimizations. The script suggested to allocate large stakes to subgraphs with an awesome allocation / signal ratio. But the signals were not that high. When allocating a large stake on these subgraphs, the optimization \"broke\" the ratio and the rewards were not correctly calculated. With this addition we now add the stake which we allocate to the subgraphs into the formular. model.rewards = pyomo.Objective( expr=sum((model.x[c] / (data[c]['stakedTokensTotal'] + sliced_stake)) * (data[c]['signalledTokensTotal'] / data[c]['SignalledNetwork']) * data[c][reward_interval] for c in C), sense=pyomo.maximize) Added Fetching Status of network subgraph (UP/DOWN) : Outputs a warning if the networ subgraph is down. Bugfixes \ud83d\udc1e \u00b6 Subgraphs where allocations have been placed but the subgraph name is not available (anymore, because of updates to the subgraph), were not correctly recognized in the optimization process Errors regarding mainnet launch were fixed Fixed Error when running optimization script without active allocations","title":"Changelog"},{"location":"8.%20Changelog/#changelog","text":"","title":"Changelog"},{"location":"8.%20Changelog/#release-103-beta","text":"","title":"Release 1.0.3 beta \ud83c\udf41"},{"location":"8.%20Changelog/#features","text":"added \"--ignore_tx_costs\" flag for ignoring gas costs for allocation openings / closings in calculating the threshold","title":"Features"},{"location":"8.%20Changelog/#bugfixes","text":"Fixed a couple of bugs regarding df_log, which has a non unique index if there are parallel allocations. Fixed bugs regarding the automatic allocation Enhanced documentation Set automation flag in web application to \"false\" Attention: The automatic allocation flag is now pushed to the main branch. But you should still set it to false or test it on testnet. There could be edge cases which aren't accounted for so far.","title":"Bugfixes \ud83d\udc1e"},{"location":"8.%20Changelog/#release-102-beta","text":"","title":"Release 1.0.2 beta \ud83e\uddea"},{"location":"8.%20Changelog/#features_1","text":"Added support for automatic allocations via the indexer agent management endpoint (127.0.0.1:18000/) SetIndexingRules to Never for closing allocations checking if allocations were succesfully closed via web3.py and eventFilters for AllocationClosed SetIndexingRules to always for creating allocations checking if allocations were succesfully created via web3.py and eventFilters for AllocationsCreated Added Selectbox for Streamlit Web App to choose automatic allocations","title":"Features"},{"location":"8.%20Changelog/#bugfixes_1","text":"Allocation Script wasn't gathering all SubgraphDeployments. Now set the limit to 1000","title":"Bugfixes \ud83d\udc1e"},{"location":"8.%20Changelog/#release-101-beta","text":"","title":"Release 1.0.1 beta \ud83d\udcc8"},{"location":"8.%20Changelog/#features_2","text":"Added support for running the optimization on testnet . Checkout the network parameter in 3. Usage and Parameters.md Added support for testnet optimization in streamlit web application. Refinement and addition of charts for historical performance tracking & GRT performance.","title":"Features"},{"location":"8.%20Changelog/#release-10-beta","text":"","title":"Release 1.0 beta \ud83d\udce4"},{"location":"8.%20Changelog/#features_3","text":"Added subgraph_health_checks.py (optional: SSH tunnel on indexer local database). Allows indexers to fetch subgraphs that have errors, are not in sync, are depreciated or are from blacklisted subgraph developers. These functions, if applied, populate the config.json blacklist element automatically and helps mitigating bot-bait subgraphs. Added automatic blacklisting for blacklisted subgraph developers. If there is a suspicious subgraph developer, the developer can be added to the config.json and the optimization script automatically blacklists all subgraphs released from this address Added automatic blacklisting of inactive (active status: False) subgraphs Added automatic blacklisting of subgraphs with bad health status (errors, not in sync Added further parameters to change the behaviour of the allocation optimization script threshold_interval: Define the interval which is used for calculating the threshold requirment. Currently the recommended threshold interval is \"weekly\". Setting the threshold interval to weekly leads the optimization script to calculate threshold requirments based on weekly indexing rewards. reserve_stake: Enables the indexer to define a dedicated amount of stake which should not be considered in the optimization. This reserve stake will not be allocated! min_allocation: Set the minimum allocation in GRT per subgraph. If this value is above 0, every deployed subgraph will get the minimum allocation amount. ATTENTION \ud83d\udea8: Setting this value above 0 leads to massive increases in transaction costs min_allocated_grt_subgraph: Defines the minimum GRT allocation requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT allocated than the min_allocated_grt_subgraph, then it will not be considered in the optimization process. min_signalled_grt_subgraph: Defines the minimum GRT signal requirment for a subgraph to be considered in the optimization process. If a subgraph have less GRT signalled than the min_signalled_grt_subgraph, then it will not be considered in the optimization process. slack_alerting: Enables the user to configure a slack alerting in a dedicated slack channel. Outputs if the optimization reached the threshold and how much increase / decrease in rewards is expected after the optimization. Configure the webhook and channel in the .env file. Refactored the codebase. Now the script isn't bundled in one script.py file. A dedicated src directory is introduced, which also includes a webapp subdirectory for the streamlit application. Included a streamlit-based web application for the optimization. The web application simplifies the usage of the optimization script. Check out the screencast of the web app Implemented historical performance tracking on daily granularity. For closed allocations the indexing rewards are calculated based on the network subgraph data. For active allocations the indexing rewards are calculated by gathering pending rewards data with rpc calls from the reward manager contract . Implemented a DIY Chart builder based on plotly. This is heavy work in progress so expect errors. Added key metrics from previous and current run Abandoned tracking logic with log files for each run. Accumulated metrics of every optimization run in a optimizer_log.json with better structure and key-value pairs. Added a POI fetching script ( poi.py ) to gather the latest acailable POIs for broken / bait subgraphs which are not correctly shown on the indexer agent. Requires a ssh tunnel to the indexer server or has to be run on the indexer server. CAUTION \u26a0\ufe0f: Always crosscheck your POIs before manually closing allocations. If possible always use the indexer CLI Added Naive Method in Optimization Script to keep the ratio of signal / stake on a subgraph. In the model.reward optimization function we added the the part (data[c]['stakedTokensTotal'] + sliced_stake) . This results in better optimizations. The script suggested to allocate large stakes to subgraphs with an awesome allocation / signal ratio. But the signals were not that high. When allocating a large stake on these subgraphs, the optimization \"broke\" the ratio and the rewards were not correctly calculated. With this addition we now add the stake which we allocate to the subgraphs into the formular. model.rewards = pyomo.Objective( expr=sum((model.x[c] / (data[c]['stakedTokensTotal'] + sliced_stake)) * (data[c]['signalledTokensTotal'] / data[c]['SignalledNetwork']) * data[c][reward_interval] for c in C), sense=pyomo.maximize) Added Fetching Status of network subgraph (UP/DOWN) : Outputs a warning if the networ subgraph is down.","title":"Features \ud83c\udd95"},{"location":"8.%20Changelog/#bugfixes_2","text":"Subgraphs where allocations have been placed but the subgraph name is not available (anymore, because of updates to the subgraph), were not correctly recognized in the optimization process Errors regarding mainnet launch were fixed Fixed Error when running optimization script without active allocations","title":"Bugfixes \ud83d\udc1e"},{"location":"9.%20Roadmap/","text":"Roadmap \u00b6 Backlog \u00b6 Enhance DIY chart builder Predefinied parameter settings for \"strategies\" API Endpoint for the optimization Alerting with Discord / Telegram Detailed Historical Performance (hourly intervalls with caching) Optimization of query fees (cobb-douglas-function) Predictive modelling of subgraph signals -> which subgraph will get additional signal Gas Optimization and Gas Estimation WIP \u00b6 Dockerizing the application script_never.txt just populates the subgraphs that are reallocated, not removing all allocations script.txt just allocating the changed allocations Download performance data as .csv Done \u00b6 Automatic allocation optimization and reallocation with cronjobs and communication with the indexe agent endpoint (requires graphQL mutations) \u2611\ufe0f Running the optimization script on testnet.\u2611\ufe0f Styling, Fixing Bugs and enhancing charts in the streamlit web application \u2611\ufe0f","title":"Roadmap"},{"location":"9.%20Roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"9.%20Roadmap/#backlog","text":"Enhance DIY chart builder Predefinied parameter settings for \"strategies\" API Endpoint for the optimization Alerting with Discord / Telegram Detailed Historical Performance (hourly intervalls with caching) Optimization of query fees (cobb-douglas-function) Predictive modelling of subgraph signals -> which subgraph will get additional signal Gas Optimization and Gas Estimation","title":"Backlog"},{"location":"9.%20Roadmap/#wip","text":"Dockerizing the application script_never.txt just populates the subgraphs that are reallocated, not removing all allocations script.txt just allocating the changed allocations Download performance data as .csv","title":"WIP"},{"location":"9.%20Roadmap/#done","text":"Automatic allocation optimization and reallocation with cronjobs and communication with the indexe agent endpoint (requires graphQL mutations) \u2611\ufe0f Running the optimization script on testnet.\u2611\ufe0f Styling, Fixing Bugs and enhancing charts in the streamlit web application \u2611\ufe0f","title":"Done"}]}